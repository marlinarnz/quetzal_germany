{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from quetzal.os.parallel_call import parallel_call_notebook, parallel_call_notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('log/'):\n",
    "    os.makedirs('log/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Â Launcher\n",
    "\n",
    "This notebook automatically launches all operations for a complete model run. One can decide to skip network preparation steps, as they take multiple hours for the region of Germany and the networks are readily included in the repository.\n",
    "\n",
    "Detailed explainations of certain steps can be found in the corresponding notebook. All ASSUMPTIONS are gathered in the `input/parameters.xls` file. This file also includes scenarios as columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'workers':4, 'errout_suffix':True, 'sleep':1,'stdout_path':r'log/out.txt', 'stderr_path':r'log/err.txt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = ['base'] #['2035_base', 'CO2-tax_210', 'road_charge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network preparation\n",
    "\n",
    "NOT required for the fist model run.\n",
    "\n",
    "Execute all `prep1` and `prep2` steps. Only neccessary if new network data or assumptions are applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 prep12_rail_coach.py base\n",
      "1 prep14_bus.py base\n",
      "subprocess **prep14_bus.py1 base** terminated with an error.\n",
      "1763 seconds\n",
      "0 prep13_air.py base\n",
      "28 seconds\n"
     ]
    }
   ],
   "source": [
    "# Network generation\n",
    "parallel_call_notebook('prep10_zones_disagg.ipynb', arg_list=scenarios, **kwargs)\n",
    "parallel_call_notebooks(\n",
    "    ('prep11_road.ipynb', scenarios),\n",
    "    ('prep12_rail_coach.ipynb', scenarios),\n",
    "    ('prep14_bus.ipynb', scenarios),\n",
    "    **kwargs)\n",
    "parallel_call_notebook('prep13_air.ipynb', arg_list=scenarios, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 prep15_census_distances.py base\n",
      "7805 seconds\n"
     ]
    }
   ],
   "source": [
    "# Access/egress distances to PT services based on networks and census data\n",
    "parallel_call_notebook('prep15_census_distances.ipynb', arg_list=scenarios, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 prep20_cluster.py base\n",
      "3099 seconds\n",
      "0 prep21_aggregate_pt.py base\n",
      "1220 seconds\n",
      "0 prep22_access_egress_road.py base\n",
      "98 seconds\n"
     ]
    }
   ],
   "source": [
    "# Network aggregation and inter-connection\n",
    "# First cluster stops, then aggregate trips\n",
    "parallel_call_notebook('prep20_cluster.ipynb', arg_list=scenarios, **kwargs)\n",
    "parallel_call_notebook('prep21_aggregate_pt.ipynb', arg_list=scenarios, **kwargs)\n",
    "# Run the aggregation twice in order to reduce bus trips properly\n",
    "parallel_call_notebook('prep21_aggregate_pt.ipynb', arg_list=scenarios, **kwargs)\n",
    "parallel_call_notebook('prep22_access_egress_road.ipynb', arg_list=scenarios, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fewer zones for modelling on a laptop\n",
    "\n",
    "If only 8GB RAM is available, the zoning system must be reduced to 401 NUTS3-level zones. The following steps create the corresponding network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_call_notebook('prep10_zones.ipynb', arg_list=scenarios, **kwargs)\n",
    "# Networks are already computed\n",
    "# Access/egress distances to PT services based on networks and census data\n",
    "parallel_call_notebook('prep15_census_distances.ipynb', arg_list=scenarios, **kwargs)\n",
    "# Network aggregation and inter-connection\n",
    "# First cluster stops, then aggregate trips\n",
    "parallel_call_notebook('prep20_cluster.ipynb', arg_list=scenarios, **kwargs)\n",
    "parallel_call_notebook('prep21_aggregate_pt.ipynb', arg_list=scenarios, **kwargs)\n",
    "parallel_call_notebook('prep22_access_egress_road.ipynb', arg_list=scenarios, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparsify the OD set for a faster, smaller model\n",
    "\n",
    "Computation of all OD pairs is not required for accurate aggregate results (pkm, choice probabilities, etc.). Hence, the OD set can be sparsified before the pathfinders are executed. The sample size is defined in the general attributes of the `parameters.xls` file. Leave the field empty for no sampling.\n",
    "\n",
    "If you sample the OD set, you don't need to compute volumes in the 4-step cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 model_volumes_endo.py base\n",
      "572 seconds\n"
     ]
    }
   ],
   "source": [
    "# Calculation of the OD matrix\n",
    "#parallel_call_notebook('model_generation_endo.ipynb', arg_list=scenarios, **kwargs)\n",
    "#parallel_call_notebook('model_distribution.ipynb', arg_list=scenarios, **kwargs)\n",
    "#parallel_call_notebook('model_volumes_exo.ipynb', arg_list=scenarios, **kwargs)\n",
    "parallel_call_notebook('model_volumes_endo.ipynb', arg_list=scenarios, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pathfinders and level of service\n",
    "\n",
    "Required for the first model run.\n",
    "\n",
    "If assumptions in `parameters.xls` are changed, the corresponding `prep3X` notebooks should be ran.\n",
    "\n",
    "Note: All upcoming steps should be run on the same computer, as intermediate model files are pickled and Python's pickle protocols are not stable across different versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 prep30_pathfinder_road.py base\n",
      "327 seconds\n",
      "0 prep31_prices_car.py base\n",
      "34 seconds\n"
     ]
    }
   ],
   "source": [
    "# Road\n",
    "parallel_call_notebook('prep30_pathfinder_road.ipynb', arg_list=scenarios, **kwargs)\n",
    "parallel_call_notebook('prep31_prices_car.ipynb', arg_list=scenarios, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 prep30_pathfinder_pt.py base\n",
      "7520 seconds\n",
      "0 prep31_prices_pt.py base\n",
      "120 seconds\n",
      "0 prep33_non-motor.py base\n",
      "18 seconds\n"
     ]
    }
   ],
   "source": [
    "# PT\n",
    "parallel_call_notebook('prep30_pathfinder_pt.ipynb', arg_list=scenarios, **kwargs)\n",
    "parallel_call_notebook('prep31_prices_pt.ipynb', arg_list=scenarios, **kwargs)\n",
    "parallel_call_notebook('prep33_non-motor.ipynb', arg_list=scenarios, **kwargs)\n",
    "# terminates with error from 'assert manual' if there is a saved versions of footpaths\n",
    "# so that it doesn't have to compute them again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation\n",
    "\n",
    "Calculation of parameters for the utility function. Data set access required (see data availability in Readme file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cal10_input_data.py base\n",
      "subprocess **cal10_input_data.py0 base** terminated with an error.\n",
      "22 seconds\n",
      "0 cal1x_validation_data.py base\n",
      "subprocess **cal1x_validation_data.py0 base** terminated with an error.\n",
      "4 seconds\n",
      "0 cal11_los_columns.py base\n",
      "72 seconds\n"
     ]
    }
   ],
   "source": [
    "# Calibration data preparation\n",
    "# NOTE: only applicapble if you have access to the calibration dataset\n",
    "#parallel_call_notebook('cal10_input_data.ipynb', arg_list=scenarios, **kwargs)\n",
    "#parallel_call_notebook('cal1x_validation_data.ipynb', arg_list=scenarios, **kwargs)\n",
    "parallel_call_notebook('cal11_los_columns_inter-zonal.ipynb', arg_list=scenarios, **kwargs)\n",
    "#parallel_call_notebook('cal19_vot.ipynb', arg_list=scenarios, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cal20_estimation.py base\n",
      "5475 seconds\n"
     ]
    }
   ],
   "source": [
    "# Estimation mode choice parameters\n",
    "# Uses all CPU cores\n",
    "parallel_call_notebook('cal20_estimation_mode.ipynb', arg_list=scenarios, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimation destination choice parameters\n",
    "# Uses all CPU cores\n",
    "parallel_call_notebook('cal21_estimation_destination.ipynb', arg_list=scenarios, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimation inner/inter zonal choice parameters\n",
    "# Uses all CPU cores\n",
    "parallel_call_notebook('cal22_estimation_inner-inter.ipynb', arg_list=scenarios, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-step modelling\n",
    "\n",
    "Except for the logit model step, all modelling steps require access to the OD volumes dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 model_generation_endo.py base\n",
      "6009 seconds\n"
     ]
    }
   ],
   "source": [
    "# Generation\n",
    "# Doesn't need to be run for the base scenario, as generation volumes\n",
    "# are already saved in the zones table\n",
    "#parallel_call_notebook('model_generation_exo.ipynb', arg_list=scenarios, **kwargs) # fixed probabilities from MiD2017\n",
    "parallel_call_notebook('model_generation_endo.ipynb', arg_list=scenarios, **kwargs) # MNL model based on MiD2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 model_destination.py base\n",
      "923 seconds\n"
     ]
    }
   ],
   "source": [
    "# Distribution choice probabilities\n",
    "parallel_call_notebook('model_destination.ipynb', arg_list=scenarios, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 model_volumes_endo.py base\n",
      "537 seconds\n"
     ]
    }
   ],
   "source": [
    "# Generation of the OD matrix\n",
    "#parallel_call_notebook('model_volumes_exo.ipynb', arg_list=scenarios, **kwargs) # volumes from VP2030\n",
    "parallel_call_notebook('model_volumes_endo.ipynb', arg_list=scenarios, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 model_logit.py base\n",
      "57 seconds\n"
     ]
    }
   ],
   "source": [
    "# Mode choice probabilities\n",
    "parallel_call_notebook('model_logit.ipynb', arg_list=scenarios, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 model_assignment.py base\n",
      "386 seconds\n"
     ]
    }
   ],
   "source": [
    "# Assignment\n",
    "parallel_call_notebook('model_assignment.ipynb', arg_list=scenarios, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equilibration\n",
    "\n",
    "Demand-supply equilibration happens iteratively for road traffic. It can be used to refine results after running the assignment step once. If so, a new model folder `<scenario name>_equilibrium` is created from which the modelling steps take their road LoS table and save the equilibrated results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the equilibrium road pathfinder to create the new LoS table\n",
    "parallel_call_notebook('model_assignment_equilibrium.ipynb', arg_list=scenarios, **kwargs)\n",
    "parallel_call_notebook('prep31_prices_car.ipynb', arg_list=scenarios, **kwargs)\n",
    "# Rename the scenarios\n",
    "scenarios = [str(s)+'_equilibrium' for s in scenarios]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demand model\n",
    "parallel_call_notebook('model_logit.ipynb', arg_list=scenarios, **kwargs)\n",
    "# Supply model\n",
    "parallel_call_notebook('model_assignment.ipynb', arg_list=scenarios, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-processing\n",
    "\n",
    "Calculate transport system indicators such as total pkm, energy demand, or GHG emissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 post_emissions.py base\n",
      "1055 seconds\n"
     ]
    }
   ],
   "source": [
    "# Post-processing\n",
    "#parallel_call_notebook('post_assignment_inner-zonal.ipynb', arg_list=scenarios, **kwargs)\n",
    "parallel_call_notebook('post_emissions.ipynb', arg_list=scenarios, **kwargs)\n",
    "#parallel_call_notebook('post_energy.ipynb', arg_list=scenarios, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Total execution time (minutes)\n",
    "int((time.time() - start) / 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
