{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0aa3e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key text.latex.preview in file C:\\Users\\marlin.arnz\\AppData\\Local\\Continuum\\miniconda3\\envs\\quetzal\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 123 ('text.latex.preview : False')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key mathtext.fallback_to_cm in file C:\\Users\\marlin.arnz\\AppData\\Local\\Continuum\\miniconda3\\envs\\quetzal\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 155 ('mathtext.fallback_to_cm : True  # When True, use symbols from the Computer Modern')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key savefig.jpeg_quality in file C:\\Users\\marlin.arnz\\AppData\\Local\\Continuum\\miniconda3\\envs\\quetzal\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 418 ('savefig.jpeg_quality: 95       # when a jpeg is saved, the default quality parameter.')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key keymap.all_axes in file C:\\Users\\marlin.arnz\\AppData\\Local\\Continuum\\miniconda3\\envs\\quetzal\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 466 ('keymap.all_axes : a                 # enable all axes')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key animation.avconv_path in file C:\\Users\\marlin.arnz\\AppData\\Local\\Continuum\\miniconda3\\envs\\quetzal\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 477 ('animation.avconv_path: avconv     # Path to avconv binary. Without full path')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key animation.avconv_args in file C:\\Users\\marlin.arnz\\AppData\\Local\\Continuum\\miniconda3\\envs\\quetzal\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 479 ('animation.avconv_args:            # Additional arguments to pass to avconv')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import sys # for automation and parallelisation\n",
    "manual, scenario = (True, 'base') if 'ipykernel' in sys.argv[0] else (False, sys.argv[1])\n",
    "if manual:\n",
    "    %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8387063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from quetzal.model import stepmodel\n",
    "from quetzal.io import excel\n",
    "import biogeme.database as db\n",
    "import biogeme.biogeme as bio\n",
    "import biogeme.models as models\n",
    "from biogeme import expressions as ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1254663e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../model/' + scenario + '/'\n",
    "input_path = '../input/'\n",
    "input_static_path = '../input_static/'\n",
    "output_path = '../output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49222b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load scenario parameters\n",
    "params = excel.read_var(file='../input/parameters.xls', scenario=scenario)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65fa6c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# OD matrix generation\n",
    "\n",
    "## Needs zone attributes and destination choice model results\n",
    "\n",
    "## Saves volumes table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e5f86b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transport demand segments\n",
    "segments = [s.strip() for s in params['general']['demand_segments'].split(';')]\n",
    "purposes = ['commuting', 'business', 'education', 'buy/execute', 'leisure', 'accompany']\n",
    "purp_n_dict = dict(zip(purposes, [1,2,3,4,6,7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69fdd177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170.00337643647052"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load zones\n",
    "sm = stepmodel.read_json(model_path + 'de_zones')\n",
    "# Sum of trips per day from generation step (million)\n",
    "sm.zones[[str((s, 'generation')) for s in segments]].sum().sum() / 1e6 / 365"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0efc25b",
   "metadata": {},
   "source": [
    "## Calculate probabilities of inner/inter-zonal choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bb947f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load employment data\n",
    "employment = pd.read_csv(input_static_path + 'spatial_employed_persons_2017_eurostat.csv', encoding='latin-1')\n",
    "employment['Value'] = (pd.to_numeric(employment['Value'].str.replace(',', '')) * 1000).astype(int)\n",
    "# Also, load NUTS-names\n",
    "nuts = gpd.read_file(input_static_path + \"spatial_NUTS_RG_01M_2016_4326.geojson\")\n",
    "nuts = nuts[(nuts[\"CNTR_CODE\"]==\"DE\") & (nuts[\"LEVL_CODE\"]==3)]\n",
    "# Map differing names of zones to names in employment data\n",
    "name_dict = {'Burgenlandkreis (DE)': 'Burgenlandkreis',\n",
    "             'Dillingen an der Donau': 'Dillingen a.d. Donau',\n",
    "             'Mühldorf am Inn': 'Mühldorf a. Inn',\n",
    "             'Neumarkt in der Oberpfalz': 'Neumarkt i. d. OPf.',\n",
    "             'Neustadt an der Aisch-Bad Windsheim': 'Neustadt a. d. Aisch-Bad Windsheim',\n",
    "             'Neustadt an der Waldnaab': 'Neustadt a. d. Waldnaab',\n",
    "             'Pfaffenhofen an der Ilm': 'Pfaffenhofen a. d. Ilm',\n",
    "             'Weiden in der Oberpfalz, Kreisfreie Stadt': 'Weiden i. d. Opf, Kreisfreie Stadt',\n",
    "             'Wunsiedel im Fichtelgebirge': 'Wunsiedel i. Fichtelgebirge'}\n",
    "employment['GEO'].replace(name_dict, inplace=True)\n",
    "zone_dict = employment.set_index('GEO')['Value'].to_dict()\n",
    "name_dict = nuts.set_index('NUTS_ID')['NUTS_NAME'].to_dict()\n",
    "sm.zones['employment'] = sm.zones['NUTS_ID'].map(name_dict).map(zone_dict) * sm.zones['pop_share']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f8f99d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill POI values\n",
    "pois = pd.read_csv(input_path + 'spatial_num_pois_raw.csv', index_col='index')\n",
    "cats = pd.read_excel(input_path + 'spatial_OSM_POI_list.xlsx', sheet_name='categories')\n",
    "cats['label'] = (cats['key'] + ' ' + cats['value'].fillna('')).str.strip()\n",
    "for category, columns in cats.loc[cats['category'].notna()\n",
    "                                 ].groupby('category').agg(\n",
    "                                {'label': list})['label'].items():\n",
    "    sm.zones[category] = sm.zones['FID'].map(pois[columns].sum(axis=1)).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abdeb7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load inter-zonal composite cost from mode choice step\n",
    "cc = pd.read_csv(output_path + scenario + '/mode_choice_od_composite_cost.csv')\n",
    "cc.set_index(['origin', 'destination'], inplace=True)\n",
    "# Rename segments to integer values\n",
    "cc.columns = pd.MultiIndex.from_tuples(\n",
    "    [(seg.split('_')[0], {'no': 0, 'car': 1}[seg.split('_')[1]])\n",
    "     for seg in cc.columns],\n",
    "    names=['purpose_model', 'car_av'])\n",
    "# Reshape the table into a mergable format\n",
    "# Use the mean CC to all destinations as accessibility\n",
    "cc = cc.unstack('destination').stack('purpose_model').stack('car_av').mean(axis=1)\n",
    "cc = cc.unstack('purpose_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f79ca8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load inner/inter choice model results\n",
    "betas = pd.read_csv(input_path + 'inner-inter_betas.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebd892ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "commuting_0 av. prob. inner: 0.56\n",
      "business_0 av. prob. inner: 0.56\n",
      "education_0 av. prob. inner: 0.56\n",
      "buy/execute_0 av. prob. inner: 0.55\n",
      "leisure_0 av. prob. inner: 0.57\n",
      "accompany_0 av. prob. inner: 0.55\n",
      "commuting_1 av. prob. inner: 0.54\n",
      "business_1 av. prob. inner: 0.54\n",
      "education_1 av. prob. inner: 0.55\n",
      "buy/execute_1 av. prob. inner: 0.54\n",
      "leisure_1 av. prob. inner: 0.55\n",
      "accompany_1 av. prob. inner: 0.54\n"
     ]
    }
   ],
   "source": [
    "# Simulate the probabilities from the zones table using biogeme\n",
    "inner_probs = pd.DataFrame(index=sm.zones.index)\n",
    "car_names = {0: '_no_car', 1: '_car'}\n",
    "for car in [0,1]:\n",
    "    for p in purposes:\n",
    "        # Add accessibility for this segment to database\n",
    "        sm.zones['acc_'+p] = sm.zones.merge(cc.xs(car, level='car_av'),\n",
    "                                            how='left', left_index=True, right_index=True\n",
    "                                           )[p]\n",
    "        # Create the database\n",
    "        zones_db = db.Database('zones', sm.zones[\n",
    "            ['employment', 'population', 'area', 'acc_'+p]\n",
    "            + list(cats.loc[cats['category'].notna(), 'category'].unique())])\n",
    "        globals().update(zones_db.variables)\n",
    "        \n",
    "        # Define utility formulations as in cal22\n",
    "        # Define parameters\n",
    "        ASC_0 = ex.Beta('ASC_0', 0, None, None, 1)\n",
    "        ASC_1 = ex.Beta('ASC_1', 0, None, None, 0)\n",
    "        b_pop = ex.Beta('b_pop', 0, None, None, 0)\n",
    "        b_attr = ex.Beta('b_attr', 0, None, None, 0)\n",
    "        b_acc = ex.Beta('b_acc', 0, None, None, 0)\n",
    "\n",
    "        # Define the utility formulation by purpose\n",
    "        if p == 'commuting':\n",
    "            V= {0:\n",
    "                ASC_0\n",
    "                + ex.log(1+employment)*b_attr\n",
    "                + ex.log((1+population)/area)*b_pop,\n",
    "                1:\n",
    "                ASC_1\n",
    "                + acc_commuting * b_acc}\n",
    "        elif p == 'business':\n",
    "            V= {0:\n",
    "                ASC_0\n",
    "                + ex.log(1+employment)*b_attr\n",
    "                + ex.log((1+population)/area)*b_pop,\n",
    "                1:\n",
    "                ASC_1\n",
    "                + acc_business * b_acc}\n",
    "        elif p == 'education':\n",
    "            V= {0:\n",
    "                ASC_0\n",
    "                + ex.log(1+childcare + school + higher_education)*b_attr\n",
    "                + ex.log((1+population)/area)*b_pop,\n",
    "                1:\n",
    "                ASC_1\n",
    "                + acc_education * b_acc}\n",
    "        elif p == 'buy/execute':\n",
    "            V= {0:\n",
    "                ASC_0\n",
    "                + ex.log(1+shop + medical + special_shop)*b_attr\n",
    "                + ex.log((1+population)/area)*b_pop,\n",
    "                1:\n",
    "                ASC_1\n",
    "                + globals()['acc_buy/execute'] * b_acc}\n",
    "        elif p == 'leisure':\n",
    "            V= {0:\n",
    "                ASC_0\n",
    "                + ex.log(1+daily_leisure + holiday + occasional_leisure)*b_attr\n",
    "                + ex.log((1+population)/area)*b_pop,\n",
    "                1:\n",
    "                ASC_1\n",
    "                + acc_leisure * b_acc}\n",
    "        elif p == 'accompany':\n",
    "            V= {0:\n",
    "                ASC_0\n",
    "                + ex.log(1+medical + school + childcare)*b_attr\n",
    "                + ex.log((1+population)/area)*b_pop,\n",
    "                1:\n",
    "                ASC_1\n",
    "                + acc_accompany * b_acc}\n",
    "        \n",
    "        # Simulate\n",
    "        simulate = {j: models.logit(V, None, int(j)) for j in [0,1]}\n",
    "        model = bio.BIOGEME(zones_db, simulate)\n",
    "        probs = model.simulate(theBetaValues=betas[p+car_names[car]].to_dict())\n",
    "        \n",
    "        # Calculate generation volumes\n",
    "        inner_probs[p+car_names[car]] = probs[0]\n",
    "        print('{}_{} av. prob. inner: {}'.format(p,car,np.round(probs[0].mean(), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9106371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If all that doesn't make sense:\n",
    "# Take inner-zonal probabilities from MiD2017 data by urbanisation degree\n",
    "#inner_probs = pd.read_csv(input_path + 'inner-zonal_probabilities_agg_urban.csv', index_col=0)\n",
    "#inner_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a90b068",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compute volumes (OD matrix)\n",
    "\n",
    "$F_{ods} = N_{os} * p^{dest}_{ods} * (1 - p^{inner}_{os})$\n",
    "\n",
    "Indecies:\n",
    "* o: origin zone\n",
    "* d: destination zone\n",
    "* s: demand segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a92f3886",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "utility_values: 100%|████████████████████████████████████████████████████████████████████| 7/7 [00:06<00:00,  1.02it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load probability results from logit step\n",
    "dm = stepmodel.read_zippedpickles(model_path + 'de_destination_choice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a19a2c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>destination</th>\n",
       "      <th>accompany_car</th>\n",
       "      <th>accompany_no_car</th>\n",
       "      <th>business_car</th>\n",
       "      <th>business_no_car</th>\n",
       "      <th>buy/execute_car</th>\n",
       "      <th>buy/execute_no_car</th>\n",
       "      <th>commuting_car</th>\n",
       "      <th>commuting_no_car</th>\n",
       "      <th>education_car</th>\n",
       "      <th>education_no_car</th>\n",
       "      <th>leisure_car</th>\n",
       "      <th>leisure_no_car</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1956600</th>\n",
       "      <td>DE27E_8</td>\n",
       "      <td>DE947_3</td>\n",
       "      <td>6.931062e-08</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>2.499961e-09</td>\n",
       "      <td>7.320332e-07</td>\n",
       "      <td>6.851113e-26</td>\n",
       "      <td>1.552545e-14</td>\n",
       "      <td>9.591187e-28</td>\n",
       "      <td>7.710394e-17</td>\n",
       "      <td>7.747360e-35</td>\n",
       "      <td>4.590916e-19</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3038124</th>\n",
       "      <td>DE938_3</td>\n",
       "      <td>DE913_0</td>\n",
       "      <td>7.123169e-05</td>\n",
       "      <td>0.001559</td>\n",
       "      <td>3.978197e-03</td>\n",
       "      <td>1.065799e-02</td>\n",
       "      <td>5.195805e-05</td>\n",
       "      <td>2.868097e-03</td>\n",
       "      <td>9.093012e-05</td>\n",
       "      <td>2.615611e-03</td>\n",
       "      <td>1.068348e-05</td>\n",
       "      <td>1.385176e-03</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          origin destination  accompany_car  accompany_no_car  business_car  \\\n",
       "1956600  DE27E_8     DE947_3   6.931062e-08          0.000023  2.499961e-09   \n",
       "3038124  DE938_3     DE913_0   7.123169e-05          0.001559  3.978197e-03   \n",
       "\n",
       "         business_no_car  buy/execute_car  buy/execute_no_car  commuting_car  \\\n",
       "1956600     7.320332e-07     6.851113e-26        1.552545e-14   9.591187e-28   \n",
       "3038124     1.065799e-02     5.195805e-05        2.868097e-03   9.093012e-05   \n",
       "\n",
       "         commuting_no_car  education_car  education_no_car  leisure_car  \\\n",
       "1956600      7.710394e-17   7.747360e-35      4.590916e-19     0.000045   \n",
       "3038124      2.615611e-03   1.068348e-05      1.385176e-03     0.001297   \n",
       "\n",
       "         leisure_no_car  \n",
       "1956600             0.0  \n",
       "3038124             0.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract probability values and create new table from it\n",
    "prob = dm.probabilities.set_index(['origin', 'segment']).drop(columns=['destination', 'root'])\n",
    "prob.columns.name = 'destination'\n",
    "volumes = prob.stack('destination').unstack('segment').reset_index()\n",
    "volumes.columns.name = None\n",
    "for seg in set(segments) - set(volumes.columns):\n",
    "    volumes[seg] = 0\n",
    "volumes.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee886f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create inner-zonal probabilities\n",
    "in_mask = volumes['origin']==volumes['destination']\n",
    "if len(volumes.loc[in_mask]) == 0:\n",
    "    volumes = volumes.append(pd.DataFrame({'origin': list(sm.zones.index),\n",
    "                                           'destination': list(sm.zones.index)})\n",
    "                            ).reset_index()\n",
    "    in_mask = volumes['origin']==volumes['destination']\n",
    "urban_dict = sm.zones['urbanisation'].to_dict()\n",
    "for seg in segments:\n",
    "    probs = inner_probs[seg]\n",
    "    # Correct probabilities in volumes\n",
    "    if len(probs) < len(sm.zones): # aggregated probabilities by urbanisation degree\n",
    "        volumes.loc[in_mask, seg] = volumes.loc[in_mask, 'origin'].map(urban_dict).map(probs)\n",
    "        volumes.loc[~in_mask, seg] = volumes.loc[~in_mask, seg] * \\\n",
    "                                     volumes.loc[~in_mask, 'origin'].map(urban_dict).map(1 - probs)\n",
    "    else:\n",
    "        volumes.loc[in_mask, seg] = volumes.loc[in_mask, 'origin'].map(probs)\n",
    "        volumes.loc[~in_mask, seg] = volumes.loc[~in_mask, seg] * \\\n",
    "                                     volumes.loc[~in_mask, 'origin'].map(1 - probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6501d9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure all probabilities sum up to 1 for each zone in each segments\n",
    "#volumes.groupby('origin')[segments].sum().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "543cab58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate number of trips\n",
    "for s in segments:\n",
    "    generation_dict = sm.zones[str((s, 'generation'))].to_dict()\n",
    "    volumes[s] = volumes[s] * volumes['origin'].map(generation_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4aae7651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157.9334806821937"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the sum (million trips per day)\n",
    "volumes[segments].sum().sum() / 1e6 / 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a723b9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.492485358015813"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inter-zonal trips (billion per year)\n",
    "volumes.loc[volumes['origin']!=volumes['destination'], segments].sum().sum() / 1e9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1cec57",
   "metadata": {},
   "source": [
    "## Sparsify the OD set\n",
    "\n",
    "Reduce the number of OD pairs to a sample while keeping the number of trips constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30ae7a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only sample, if the parameter is specified\n",
    "sample_size = params['general']['od_sparse_sample']\n",
    "if sample_size > 0:\n",
    "    # Set a stable seed, generating the same OD set in every scenario run\n",
    "    np.random.seed(42)\n",
    "    # Choice probabilities of OD pairs weighted by trip volumes\n",
    "    od_probabilities = volumes[segments].sum(axis=1) / volumes[segments].sum().sum()\n",
    "    sample = np.random.choice(a=volumes.index,\n",
    "                              size=sample_size,\n",
    "                              p=od_probabilities)\n",
    "    # Reduce the volumes matrix\n",
    "    for seg in segments:\n",
    "        expansion = volumes[seg].sum() / sample_size\n",
    "        volumes[seg] = pd.Series(sample).value_counts() * expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2853d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157.9334806821937"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the sum (million trips per day)\n",
    "volumes.loc[volumes.notna().all(axis=1), segments].sum().sum() / 365 / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4ed1a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes = volumes.loc[volumes.notna().all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e4c4cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28c3cca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "volumes: 100%|████████████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 218.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# Save volumes table\n",
    "sm.volumes = volumes.reset_index(drop=True)\n",
    "sm.to_zippedpickles(model_path + 'de_volumes', only_attributes=['volumes'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
