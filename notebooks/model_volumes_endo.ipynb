{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0aa3e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys # for automation and parallelisation\n",
    "manual, scenario = (True, 'base') if 'ipykernel' in sys.argv[0] else (False, sys.argv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8387063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTables is not installed. No support for HDF output.\n",
      "SQLalchemy is not installed. No support for SQL output.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from quetzal.model import stepmodel\n",
    "from quetzal.engine.engine import od_volume_from_zones\n",
    "from quetzal.io import excel\n",
    "import biogeme.database as db\n",
    "import biogeme.biogeme as bio\n",
    "import biogeme.models as models\n",
    "from biogeme import expressions as ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1254663e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../model/' + scenario + '/'\n",
    "input_path = '../input/'\n",
    "input_static_path = '../input_static/'\n",
    "output_path = '../output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49222b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load scenario parameters\n",
    "params = excel.read_var(file='../input/parameters.xls', scenario=scenario)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65fa6c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# OD matrix generation\n",
    "\n",
    "## Needs zone attributes and destination choice model results\n",
    "\n",
    "## Saves volumes table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e5f86b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transport demand segments\n",
    "segments = [s.strip() for s in params['general']['demand_segments'].split(';')]\n",
    "purposes_compulsory = ['commuting', 'business', 'education']\n",
    "purposes_optional = ['buy/execute', 'leisure', 'accompany']\n",
    "segments_compulsory = [s for s in segments if s.split('_')[0] in purposes_compulsory]\n",
    "segments_optional = [s for s in segments if s.split('_')[0] in purposes_optional]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69fdd177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load zones\n",
    "sm = stepmodel.read_json(model_path + 'de_zones')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0efc25b",
   "metadata": {},
   "source": [
    "## Calculate probabilities of inner/inter-zonal choice for optional trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f8f99d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill POI values\n",
    "pois = pd.read_csv(input_path + 'spatial_num_pois_raw.csv', index_col='index')\n",
    "cats = pd.read_excel(input_path + 'spatial_OSM_POI_list.xlsx', sheet_name='categories')\n",
    "cats['label'] = (cats['key'] + ' ' + cats['value'].fillna('')).str.strip()\n",
    "for category, columns in cats.loc[cats['category'].notna()\n",
    "                                 ].groupby('category').agg(\n",
    "                                {'label': list})['label'].items():\n",
    "    sm.zones[category] = sm.zones['FID'].map(pois[columns].sum(axis=1)).fillna(0) \\\n",
    "                         * sm.zones['urbanisation'].map(params['poi_change']).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abdeb7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load inter-zonal composite cost from mode choice step\n",
    "try:\n",
    "    cc = pd.read_csv(output_path + scenario + '/mode_choice_od_composite_cost.csv')\n",
    "except FileNotFoundError:\n",
    "    try:\n",
    "        cc = pd.read_csv(output_path + 'base' + '/mode_choice_od_composite_cost.csv')\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(\n",
    "            'You can compute composite cost with the mode choice model or download them in the latest major release')\n",
    "cc.set_index(['origin', 'destination'], inplace=True)\n",
    "# Rename segments to integer values\n",
    "cc.columns = pd.MultiIndex.from_tuples(\n",
    "    [(seg.split('_')[0], {'no': 0, 'car': 1}[seg.split('_')[1]])\n",
    "     for seg in cc.columns],\n",
    "    names=['purpose_model', 'car_av'])\n",
    "# Reshape the table into a mergable format\n",
    "# Use the mean CC to all destinations as accessibility\n",
    "cc = cc.unstack('destination').stack('purpose_model').stack('car_av').mean(axis=1)\n",
    "cc = cc.unstack('purpose_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f79ca8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load inner/inter choice model results\n",
    "try:\n",
    "    betas = pd.read_csv(input_path + 'inner-inter_betas_{}.csv'.format(scenario), index_col=0)\n",
    "except FileNotFoundError:\n",
    "    betas = pd.read_csv(input_path + 'inner-inter_betas.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebd892ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate the probabilities from the zones table using biogeme\n",
    "inner_probs = pd.DataFrame(index=sm.zones.index)\n",
    "car_names = {0: '_no_car', 1: '_car'}\n",
    "for car in [0,1]:\n",
    "    for p in purposes_optional:\n",
    "        # Add accessibility for this segment to database\n",
    "        sm.zones['acc_'+p] = sm.zones.merge(cc.xs(car, level='car_av'),\n",
    "                                            how='left', left_index=True, right_index=True\n",
    "                                           )[p]\n",
    "        # Create the database\n",
    "        zones_db = db.Database('zones', sm.zones.loc[\n",
    "            sm.zones['acc_'+p].notna(), # might be NaN from previous sampling in mode choice step\n",
    "            ['employment', 'population', 'area', 'acc_'+p]\n",
    "            + list(cats.loc[cats['category'].notna(), 'category'].unique())])\n",
    "        globals().update(zones_db.variables)\n",
    "        \n",
    "        # Define utility formulations as in cal22\n",
    "        # Define parameters\n",
    "        ASC_0 = ex.Beta('ASC_0', 0, None, None, 1)\n",
    "        ASC_1 = ex.Beta('ASC_1', 0, None, None, 0)\n",
    "        b_pop = ex.Beta('b_pop', 0, None, None, 0)\n",
    "        b_attr = ex.Beta('b_attr', 0, None, None, 0)\n",
    "        b_acc = ex.Beta('b_acc', 0, None, None, 0)\n",
    "\n",
    "        # Define the utility formulation by purpose\n",
    "        if p == 'commuting':\n",
    "            V= {0:\n",
    "                ASC_0\n",
    "                + ex.log(1+globals()['employment'])*b_attr\n",
    "                + ex.log((1+globals()['population'])/globals()['area'])*b_pop,\n",
    "                1:\n",
    "                ASC_1\n",
    "                + globals()['acc_commuting'] * b_acc}\n",
    "        elif p == 'business':\n",
    "            V= {0:\n",
    "                ASC_0\n",
    "                + ex.log(1+globals()['employment'])*b_attr\n",
    "                + ex.log((1+globals()['population'])/globals()['area'])*b_pop,\n",
    "                1:\n",
    "                ASC_1\n",
    "                + globals()['acc_business'] * b_acc}\n",
    "        elif p == 'education':\n",
    "            V= {0:\n",
    "                ASC_0\n",
    "                + ex.log(1+globals()['childcare'] + globals()['school'] + globals()['higher_education'])*b_attr\n",
    "                + ex.log((1+globals()['population'])/globals()['area'])*b_pop,\n",
    "                1:\n",
    "                ASC_1\n",
    "                + globals()['acc_education'] * b_acc}\n",
    "        elif p == 'buy/execute':\n",
    "            V= {0:\n",
    "                ASC_0\n",
    "                + ex.log(1+globals()['shop'] + globals()['medical'] + globals()['special_shop'])*b_attr\n",
    "                + ex.log((1+globals()['population'])/globals()['area'])*b_pop,\n",
    "                1:\n",
    "                ASC_1\n",
    "                + globals()['acc_buy/execute'] * b_acc}\n",
    "        elif p == 'leisure':\n",
    "            V= {0:\n",
    "                ASC_0\n",
    "                + ex.log(1+globals()['daily_leisure'] + globals()['holiday'] + globals()['occasional_leisure'])*b_attr\n",
    "                + ex.log((1+globals()['population'])/globals()['area'])*b_pop,\n",
    "                1:\n",
    "                ASC_1\n",
    "                + globals()['acc_leisure'] * b_acc}\n",
    "        elif p == 'accompany':\n",
    "            V= {0:\n",
    "                ASC_0\n",
    "                + ex.log(1+globals()['medical'] + globals()['school'] + globals()['childcare'])*b_attr\n",
    "                + ex.log((1+globals()['population'])/globals()['area'])*b_pop,\n",
    "                1:\n",
    "                ASC_1\n",
    "                + globals()['acc_accompany'] * b_acc}\n",
    "        \n",
    "        # Simulate\n",
    "        simulate = {j: models.logit(V, None, int(j)) for j in [0,1]}\n",
    "        model = bio.BIOGEME(zones_db, simulate, numberOfThreads=1)\n",
    "        probs = model.simulate(theBetaValues=betas[p+car_names[car]].to_dict())\n",
    "        \n",
    "        # Calculate generation volumes\n",
    "        inner_probs[p+car_names[car]] = probs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9106371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If all that doesn't make sense:\n",
    "# Take inner-zonal probabilities from MiD2017 data by urbanisation degree\n",
    "#inner_probs = pd.read_csv(input_path + 'inner-zonal_probabilities_agg_urban.csv', index_col=0)\n",
    "#inner_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a90b068",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compute volumes (OD matrix) for optional trips\n",
    "\n",
    "$F_{ods} = N_{os} * p^{dest}_{ods} * (1 - p^{inner}_{os})$\n",
    "\n",
    "Indecies:\n",
    "* o: origin zone\n",
    "* d: destination zone\n",
    "* s: demand segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a92f3886",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "utility_values: 100%|████████████████████████████████████████████████████████████████████| 7/7 [00:03<00:00,  2.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load probability results from logit step\n",
    "try:\n",
    "    dm = stepmodel.read_zippedpickles(model_path + 'de_destination_choice')\n",
    "except FileNotFoundError:\n",
    "    dm = stepmodel.read_zippedpickles(model_path.replace(scenario, 'base') + 'de_destination_choice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a19a2c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>destination</th>\n",
       "      <th>accompany_car</th>\n",
       "      <th>accompany_no_car</th>\n",
       "      <th>buy/execute_car</th>\n",
       "      <th>buy/execute_no_car</th>\n",
       "      <th>leisure_car</th>\n",
       "      <th>leisure_no_car</th>\n",
       "      <th>business_car</th>\n",
       "      <th>education_no_car</th>\n",
       "      <th>commuting_car</th>\n",
       "      <th>education_car</th>\n",
       "      <th>commuting_no_car</th>\n",
       "      <th>business_no_car</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1993453</th>\n",
       "      <td>DE406_2</td>\n",
       "      <td>DE133_1</td>\n",
       "      <td>1.108507e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>8.238047e-26</td>\n",
       "      <td>8.899790e-13</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>5.745226e-09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651911</th>\n",
       "      <td>DEA47_1</td>\n",
       "      <td>DEA29_2</td>\n",
       "      <td>6.177531e-07</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>7.556094e-09</td>\n",
       "      <td>2.408245e-05</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>2.702592e-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          origin destination  accompany_car  accompany_no_car  \\\n",
       "1993453  DE406_2     DE133_1   1.108507e-07          0.000002   \n",
       "3651911  DEA47_1     DEA29_2   6.177531e-07          0.000023   \n",
       "\n",
       "         buy/execute_car  buy/execute_no_car  leisure_car  leisure_no_car  \\\n",
       "1993453     8.238047e-26        8.899790e-13     0.000005    5.745226e-09   \n",
       "3651911     7.556094e-09        2.408245e-05     0.000024    2.702592e-04   \n",
       "\n",
       "         business_car  education_no_car  commuting_car  education_car  \\\n",
       "1993453             0                 0              0              0   \n",
       "3651911             0                 0              0              0   \n",
       "\n",
       "         commuting_no_car  business_no_car  \n",
       "1993453                 0                0  \n",
       "3651911                 0                0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract probability values and create new table from it\n",
    "prob = dm.probabilities.set_index(['origin', 'segment']).drop(columns=['destination', 'root'])\n",
    "prob.columns.name = 'destination'\n",
    "volumes = prob.stack('destination').unstack('segment').reset_index()\n",
    "volumes.columns.name = None\n",
    "# Fill 0 for segments that were not covered by logit models\n",
    "for seg in set(segments) - set(volumes.columns):\n",
    "    volumes[seg] = 0\n",
    "volumes.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d15af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop empty rows\n",
    "volumes = volumes.loc[volumes[segments].sum(axis=1)>0]\n",
    "len(volumes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee886f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create inner-zonal probabilities\n",
    "in_mask = volumes['origin']==volumes['destination']\n",
    "zone_list = list(set(volumes['origin']))\n",
    "if len(volumes.loc[in_mask]) == 0:\n",
    "    volumes = pd.concat([volumes,\n",
    "                         pd.DataFrame({'origin': zone_list,\n",
    "                                       'destination': zone_list})\n",
    "                        ]).reset_index()\n",
    "    in_mask = volumes['origin']==volumes['destination']\n",
    "urban_dict = sm.zones['urbanisation'].to_dict()\n",
    "for seg in segments_optional:\n",
    "    probs = inner_probs[seg]\n",
    "    # Correct probabilities in volumes\n",
    "    if len(probs) < len(zone_list): # aggregated probabilities by urbanisation degree\n",
    "        volumes.loc[in_mask, seg] = volumes.loc[in_mask, 'origin'].map(urban_dict).map(probs)\n",
    "        volumes.loc[~in_mask, seg] = volumes.loc[~in_mask, seg] * \\\n",
    "                                     volumes.loc[~in_mask, 'origin'].map(urban_dict).map(1 - probs)\n",
    "    else:\n",
    "        volumes.loc[in_mask, seg] = volumes.loc[in_mask, 'origin'].map(probs)\n",
    "        volumes.loc[~in_mask, seg] = volumes.loc[~in_mask, seg] * \\\n",
    "                                     volumes.loc[~in_mask, 'origin'].map(1 - probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6501d9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure all probabilities sum up to 1 for each zone in each segments\n",
    "#volumes.groupby('origin')[segments_optional].sum().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "543cab58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate number of trips\n",
    "try:\n",
    "    generation = pd.read_csv(model_path + 'generation_volumes.csv', index_col=0)\n",
    "except FileNotFoundError:\n",
    "    generation = pd.read_csv(model_path.replace(scenario, 'base') + 'generation_volumes.csv', index_col=0)\n",
    "# Manually correct the choice model\n",
    "correct = params['correction_generation'].astype(float)\n",
    "for s in segments_optional:\n",
    "    volumes[s] = volumes[s] * volumes['origin'].map(generation[s]) * correct[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4aae7651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127.2037539287193"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the sum (million trips per day)\n",
    "print('Million trips per day: {}'.format(volumes[segments_optional].sum().sum() / 1e6 / 365))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a723b9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.335694337327656"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inter-zonal trips (billion per year)\n",
    "volumes.loc[volumes['origin']!=volumes['destination'], segments_optional].sum().sum() / 1e9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497cdcb6-9691-4df5-badc-652efe4ac5c2",
   "metadata": {},
   "source": [
    "## Sparsify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aadd513-c298-4361-b9d6-b80ae7b28d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OD set\n",
    "try:\n",
    "    od_set = json.load(open(model_path + 'od_set.json'))\n",
    "    od_set = [tuple(l) for l in od_set]\n",
    "    print('Found OD set with {} pairs'.format(len(od_set)))\n",
    "    volumes = volumes.set_index(['origin', 'destination']).loc[od_set].reset_index()\n",
    "    print('Million trips per day after sparsification: {}'.format(\n",
    "        volumes[segments].sum().sum() / 1e6 / 365))\n",
    "except FileNotFoundError:\n",
    "    print('Saving the full OD set')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297fb36a",
   "metadata": {},
   "source": [
    "## Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67609078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-purpose densified quarters in agglomeration areas around large cities\n",
    "max_dist = params['trip_reduction_suburban_quarters']['max_dist_to_city']\n",
    "if max_dist > 0:\n",
    "    # Find quarters\n",
    "    zones = gpd.GeoDataFrame(sm.zones, crs=sm.epsg).to_crs('EPSG:5234') # distance to meter\n",
    "    cities = zones.loc[(zones['urbanisation']==1) & (zones['population']>200000)]\n",
    "    centroids = gpd.GeoDataFrame(index=zones.loc[zones['urbanisation']==2].index,\n",
    "                                 geometry=zones.loc[zones['urbanisation']==2, 'geometry'].centroid)\n",
    "    quarters = gpd.sjoin_nearest(centroids, cities[['geometry']], max_distance=max_dist)\n",
    "    # Reduce trips\n",
    "    for seg in segments:\n",
    "        volumes.loc[volumes['origin'].isin(quarters.index), seg] *= \\\n",
    "            1 - params['trip_reduction_suburban_quarters'][seg]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e4c4cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28c3cca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "volumes: 100%|███████████████████████████████████████████████████████████████████████████| 9/9 [00:24<00:00,  2.67s/it]\n"
     ]
    }
   ],
   "source": [
    "# Save volumes table\n",
    "sm.volumes = volumes.reset_index(drop=True)\n",
    "sm.to_zippedpickles(model_path + 'de_volumes_choice', only_attributes=['volumes'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
