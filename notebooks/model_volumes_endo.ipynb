{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0aa3e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys # for automation and parallelisation\n",
    "manual, scenario = (True, 'base') if 'ipykernel' in sys.argv[0] else (False, sys.argv[1])\n",
    "if manual:\n",
    "    %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8387063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTables is not installed. No support for HDF output.\n",
      "SQLalchemy is not installed. No support for SQL output.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from quetzal.model import stepmodel\n",
    "from quetzal.engine.engine import od_volume_from_zones\n",
    "from quetzal.io import excel\n",
    "import biogeme.database as db\n",
    "import biogeme.biogeme as bio\n",
    "import biogeme.models as models\n",
    "from biogeme import expressions as ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1254663e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../model/' + scenario + '/'\n",
    "input_path = '../input/'\n",
    "input_static_path = '../input_static/'\n",
    "output_path = '../output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49222b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load scenario parameters\n",
    "params = excel.read_var(file='../input/parameters.xls', scenario=scenario)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65fa6c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# OD matrix generation\n",
    "\n",
    "## Needs zone attributes and destination choice model results\n",
    "\n",
    "## Saves volumes table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e5f86b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transport demand segments\n",
    "segments = [s.strip() for s in params['general']['demand_segments'].split(';')]\n",
    "purposes_compulsory = ['commuting', 'business', 'education']\n",
    "purposes_optional = ['buy/execute', 'leisure', 'accompany']\n",
    "segments_compulsory = [s for s in segments if s.split('_')[0] in purposes_compulsory]\n",
    "segments_optional = [s for s in segments if s.split('_')[0] in purposes_optional]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69fdd177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load zones\n",
    "sm = stepmodel.read_json(model_path + 'de_zones')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0efc25b",
   "metadata": {},
   "source": [
    "## Calculate probabilities of inner/inter-zonal choice for optional trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f8f99d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill POI values\n",
    "pois = pd.read_csv(input_path + 'spatial_num_pois_raw.csv', index_col='index')\n",
    "cats = pd.read_excel(input_path + 'spatial_OSM_POI_list.xlsx', sheet_name='categories')\n",
    "cats['label'] = (cats['key'] + ' ' + cats['value'].fillna('')).str.strip()\n",
    "for category, columns in cats.loc[cats['category'].notna()\n",
    "                                 ].groupby('category').agg(\n",
    "                                {'label': list})['label'].items():\n",
    "    sm.zones[category] = sm.zones['FID'].map(pois[columns].sum(axis=1)).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abdeb7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load inter-zonal composite cost from mode choice step\n",
    "cc = pd.read_csv(output_path + scenario + '/mode_choice_od_composite_cost.csv')\n",
    "cc.set_index(['origin', 'destination'], inplace=True)\n",
    "# Rename segments to integer values\n",
    "cc.columns = pd.MultiIndex.from_tuples(\n",
    "    [(seg.split('_')[0], {'no': 0, 'car': 1}[seg.split('_')[1]])\n",
    "     for seg in cc.columns],\n",
    "    names=['purpose_model', 'car_av'])\n",
    "# Reshape the table into a mergable format\n",
    "# Use the mean CC to all destinations as accessibility\n",
    "cc = cc.unstack('destination').stack('purpose_model').stack('car_av').mean(axis=1)\n",
    "cc = cc.unstack('purpose_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f79ca8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load inner/inter choice model results\n",
    "betas = pd.read_csv(input_path + 'inner-inter_betas.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebd892ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate the probabilities from the zones table using biogeme\n",
    "inner_probs = pd.DataFrame(index=sm.zones.index)\n",
    "car_names = {0: '_no_car', 1: '_car'}\n",
    "for car in [0,1]:\n",
    "    for p in purposes_optional:\n",
    "        # Add accessibility for this segment to database\n",
    "        sm.zones['acc_'+p] = sm.zones.merge(cc.xs(car, level='car_av'),\n",
    "                                            how='left', left_index=True, right_index=True\n",
    "                                           )[p]\n",
    "        # Create the database\n",
    "        zones_db = db.Database('zones', sm.zones.loc[\n",
    "            sm.zones['acc_'+p].notna(), # might be NaN from previous sampling in mode choice step\n",
    "            ['employment', 'population', 'area', 'acc_'+p]\n",
    "            + list(cats.loc[cats['category'].notna(), 'category'].unique())])\n",
    "        globals().update(zones_db.variables)\n",
    "        \n",
    "        # Define utility formulations as in cal22\n",
    "        # Define parameters\n",
    "        ASC_0 = ex.Beta('ASC_0', 0, None, None, 1)\n",
    "        ASC_1 = ex.Beta('ASC_1', 0, None, None, 0)\n",
    "        b_pop = ex.Beta('b_pop', 0, None, None, 0)\n",
    "        b_attr = ex.Beta('b_attr', 0, None, None, 0)\n",
    "        b_acc = ex.Beta('b_acc', 0, None, None, 0)\n",
    "\n",
    "        # Define the utility formulation by purpose\n",
    "        if p == 'commuting':\n",
    "            V= {0:\n",
    "                ASC_0\n",
    "                + ex.log(1+globals()['employment'])*b_attr\n",
    "                + ex.log((1+globals()['population'])/globals()['area'])*b_pop,\n",
    "                1:\n",
    "                ASC_1\n",
    "                + globals()['acc_commuting'] * b_acc}\n",
    "        elif p == 'business':\n",
    "            V= {0:\n",
    "                ASC_0\n",
    "                + ex.log(1+globals()['employment'])*b_attr\n",
    "                + ex.log((1+globals()['population'])/globals()['area'])*b_pop,\n",
    "                1:\n",
    "                ASC_1\n",
    "                + globals()['acc_business'] * b_acc}\n",
    "        elif p == 'education':\n",
    "            V= {0:\n",
    "                ASC_0\n",
    "                + ex.log(1+globals()['childcare'] + globals()['school'] + globals()['higher_education'])*b_attr\n",
    "                + ex.log((1+globals()['population'])/globals()['area'])*b_pop,\n",
    "                1:\n",
    "                ASC_1\n",
    "                + globals()['acc_education'] * b_acc}\n",
    "        elif p == 'buy/execute':\n",
    "            V= {0:\n",
    "                ASC_0\n",
    "                + ex.log(1+globals()['shop'] + globals()['medical'] + globals()['special_shop'])*b_attr\n",
    "                + ex.log((1+globals()['population'])/globals()['area'])*b_pop,\n",
    "                1:\n",
    "                ASC_1\n",
    "                + globals()['acc_buy/execute'] * b_acc}\n",
    "        elif p == 'leisure':\n",
    "            V= {0:\n",
    "                ASC_0\n",
    "                + ex.log(1+globals()['daily_leisure'] + globals()['holiday'] + globals()['occasional_leisure'])*b_attr\n",
    "                + ex.log((1+globals()['population'])/globals()['area'])*b_pop,\n",
    "                1:\n",
    "                ASC_1\n",
    "                + globals()['acc_leisure'] * b_acc}\n",
    "        elif p == 'accompany':\n",
    "            V= {0:\n",
    "                ASC_0\n",
    "                + ex.log(1+globals()['medical'] + globals()['school'] + globals()['childcare'])*b_attr\n",
    "                + ex.log((1+globals()['population'])/globals()['area'])*b_pop,\n",
    "                1:\n",
    "                ASC_1\n",
    "                + globals()['acc_accompany'] * b_acc}\n",
    "        \n",
    "        # Simulate\n",
    "        simulate = {j: models.logit(V, None, int(j)) for j in [0,1]}\n",
    "        model = bio.BIOGEME(zones_db, simulate, numberOfThreads=1)\n",
    "        probs = model.simulate(theBetaValues=betas[p+car_names[car]].to_dict())\n",
    "        \n",
    "        # Calculate generation volumes\n",
    "        inner_probs[p+car_names[car]] = probs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9106371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If all that doesn't make sense:\n",
    "# Take inner-zonal probabilities from MiD2017 data by urbanisation degree\n",
    "#inner_probs = pd.read_csv(input_path + 'inner-zonal_probabilities_agg_urban.csv', index_col=0)\n",
    "#inner_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a90b068",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compute volumes (OD matrix) for optional trips\n",
    "\n",
    "$F_{ods} = N_{os} * p^{dest}_{ods} * (1 - p^{inner}_{os})$\n",
    "\n",
    "Indecies:\n",
    "* o: origin zone\n",
    "* d: destination zone\n",
    "* s: demand segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a92f3886",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "utility_values: 100%|████████████████████████████████████████████████████████████████████| 7/7 [00:03<00:00,  2.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load probability results from logit step\n",
    "dm = stepmodel.read_zippedpickles(model_path + 'de_destination_choice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a19a2c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>destination</th>\n",
       "      <th>accompany_car</th>\n",
       "      <th>accompany_no_car</th>\n",
       "      <th>buy/execute_car</th>\n",
       "      <th>buy/execute_no_car</th>\n",
       "      <th>leisure_car</th>\n",
       "      <th>leisure_no_car</th>\n",
       "      <th>business_car</th>\n",
       "      <th>education_no_car</th>\n",
       "      <th>commuting_car</th>\n",
       "      <th>education_car</th>\n",
       "      <th>commuting_no_car</th>\n",
       "      <th>business_no_car</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1993453</th>\n",
       "      <td>DE406_2</td>\n",
       "      <td>DE133_1</td>\n",
       "      <td>1.108507e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>8.238047e-26</td>\n",
       "      <td>8.899790e-13</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>5.745226e-09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651911</th>\n",
       "      <td>DEA47_1</td>\n",
       "      <td>DEA29_2</td>\n",
       "      <td>6.177531e-07</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>7.556094e-09</td>\n",
       "      <td>2.408245e-05</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>2.702592e-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          origin destination  accompany_car  accompany_no_car  \\\n",
       "1993453  DE406_2     DE133_1   1.108507e-07          0.000002   \n",
       "3651911  DEA47_1     DEA29_2   6.177531e-07          0.000023   \n",
       "\n",
       "         buy/execute_car  buy/execute_no_car  leisure_car  leisure_no_car  \\\n",
       "1993453     8.238047e-26        8.899790e-13     0.000005    5.745226e-09   \n",
       "3651911     7.556094e-09        2.408245e-05     0.000024    2.702592e-04   \n",
       "\n",
       "         business_car  education_no_car  commuting_car  education_car  \\\n",
       "1993453             0                 0              0              0   \n",
       "3651911             0                 0              0              0   \n",
       "\n",
       "         commuting_no_car  business_no_car  \n",
       "1993453                 0                0  \n",
       "3651911                 0                0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract probability values and create new table from it\n",
    "prob = dm.probabilities.set_index(['origin', 'segment']).drop(columns=['destination', 'root'])\n",
    "prob.columns.name = 'destination'\n",
    "volumes = prob.stack('destination').unstack('segment').reset_index()\n",
    "volumes.columns.name = None\n",
    "# Fill 0 for segments that were not covered by logit models\n",
    "for seg in set(segments) - set(volumes.columns):\n",
    "    volumes[seg] = 0\n",
    "volumes.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee886f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create inner-zonal probabilities\n",
    "in_mask = volumes['origin']==volumes['destination']\n",
    "zone_list = list(set(volumes['origin']))\n",
    "if len(volumes.loc[in_mask]) == 0:\n",
    "    volumes = volumes.append(pd.DataFrame({'origin': zone_list,\n",
    "                                           'destination': zone_list})).reset_index()\n",
    "    in_mask = volumes['origin']==volumes['destination']\n",
    "urban_dict = sm.zones['urbanisation'].to_dict()\n",
    "for seg in segments_optional:\n",
    "    probs = inner_probs[seg]\n",
    "    # Correct probabilities in volumes\n",
    "    if len(probs) < len(zone_list): # aggregated probabilities by urbanisation degree\n",
    "        volumes.loc[in_mask, seg] = volumes.loc[in_mask, 'origin'].map(urban_dict).map(probs)\n",
    "        volumes.loc[~in_mask, seg] = volumes.loc[~in_mask, seg] * \\\n",
    "                                     volumes.loc[~in_mask, 'origin'].map(urban_dict).map(1 - probs)\n",
    "    else:\n",
    "        volumes.loc[in_mask, seg] = volumes.loc[in_mask, 'origin'].map(probs)\n",
    "        volumes.loc[~in_mask, seg] = volumes.loc[~in_mask, seg] * \\\n",
    "                                     volumes.loc[~in_mask, 'origin'].map(1 - probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6501d9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure all probabilities sum up to 1 for each zone in each segments\n",
    "#volumes.groupby('origin')[segments_optional].sum().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "543cab58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate number of trips\n",
    "generation = pd.read_csv(input_path + 'generation_volumes.csv', index_col=0)\n",
    "# Manually correct the choice model\n",
    "correct = {s: 1.2 for s in segments}\n",
    "correct['buy/execute_no_car'] *= 0.2\n",
    "correct['leisure_no_car'] *= 0.2\n",
    "correct['accompany_no_car'] *= 0.2\n",
    "for s in segments_optional:\n",
    "    volumes[s] = volumes[s] * volumes['origin'].map(generation[s]) * correct[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4aae7651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127.2037539287193"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the sum (million trips per day)\n",
    "volumes[segments_optional].sum().sum() / 1e6 / 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a723b9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.335694337327656"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inter-zonal trips (billion per year)\n",
    "volumes.loc[volumes['origin']!=volumes['destination'], segments_optional].sum().sum() / 1e9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858b7f54",
   "metadata": {},
   "source": [
    "## Compulsory trips\n",
    "\n",
    "Choose the doubly constrained gravity model as distribution method because logit models don't perform well for purposes commuting, business and education."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f786b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.zones.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21059c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load inter-zonal composite cost from mode choice step\n",
    "cc = pd.read_csv(output_path + scenario + '/mode_choice_od_composite_cost.csv')\n",
    "cc.set_index(['origin', 'destination'], inplace=True)\n",
    "cc.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f3df61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the resistance to move (composite cost from mode choice)\n",
    "distances = pd.read_csv(output_path + 'distances_centroids.csv')\n",
    "distances.set_index(['origin', 'destination'], inplace=True)\n",
    "def get_deterrence(segment, exp=1):\n",
    "    # Restrict to a distance threshold\n",
    "    merged = pd.merge(cc[segment], distances.fillna(1000), how='left',\n",
    "                      left_index=True, right_index=True)\n",
    "    merged.loc[merged['length']>params['distribution_cutoff'][segment], segment] = 1e6\n",
    "    deterrence_matrix = merged[segment].unstack('destination')\n",
    "    # Add inner-zonal resistance: the minimum\n",
    "    for z in deterrence_matrix.index:\n",
    "        deterrence_matrix.loc[z,z] = deterrence_matrix.min(axis=1)[z]\n",
    "    return np.power(deterrence_matrix.fillna(deterrence_matrix.max() * 10), -exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0446b1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute volumes from emission and attraction for a given segment\n",
    "def compute_volumes(segment, emission, attraction, exp=1):\n",
    "    sm.zones['emission'] = emission\n",
    "    sm.zones['attraction'] = attraction\n",
    "    vol = od_volume_from_zones(sm.zones, get_deterrence(segment, exp))\n",
    "    volumes[segment] = volumes.merge(vol, how='left', on=['origin', 'destination']\n",
    "                                    )['volume'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05a14356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volumes for commuting\n",
    "days = params['generation']['days_at_work_with_car']\n",
    "compute_volumes('commuting_car',\n",
    "                sm.zones['employed'] * sm.zones['car_avail_hh'] * days * 2,\n",
    "                sm.zones['employment'] * sm.zones['car_avail_hh'] * days * 2,\n",
    "                params['distribution_exponent']['commuting_car']\n",
    "               )\n",
    "days = params['generation']['days_at_work_without_car']\n",
    "compute_volumes('commuting_no_car',\n",
    "                sm.zones['employed'] * (1 - sm.zones['car_avail_hh']) * days * 2,\n",
    "                sm.zones['employment'] * (1 - sm.zones['car_avail_hh']) * days * 2,\n",
    "                params['distribution_exponent']['commuting_no_car']\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba42a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volumes for business\n",
    "# Average business trips per day from employed persons\n",
    "days = params['generation']['days_at_work_with_car']\n",
    "factor = params['generation']['business_trip_factor_with_car']\n",
    "compute_volumes('business_car',\n",
    "                sm.zones['employed'] * sm.zones['car_avail_hh'] * days * 2 * factor,\n",
    "                sm.zones['employment'] * sm.zones['car_avail_hh'] * days * 2 * factor,\n",
    "                params['distribution_exponent']['business_car']\n",
    "               )\n",
    "factor = params['generation']['business_trip_factor_without_car']\n",
    "compute_volumes('business_no_car',\n",
    "                sm.zones['employed'] * (1 - sm.zones['car_avail_hh']) * days * 2 * factor,\n",
    "                sm.zones['employment'] * (1 - sm.zones['car_avail_hh']) * days * 2 * factor,\n",
    "                params['distribution_exponent']['business_car']\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f11f9523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for education\n",
    "age_groups = pd.read_csv(input_static_path + 'spatial_Zensus_ages_2017_GENESIS.csv',\n",
    "                         encoding='latin-1', sep=';', skiprows=5, skipfooter=4, na_values='-').dropna()\n",
    "age_groups.rename(columns={'Unnamed: 1': 'lau_id'}, inplace=True)\n",
    "age_groups.loc[age_groups['lau_id']==16056, 'lau_id'] = 16063 # Update Eisenach\n",
    "age_groups = age_groups.groupby('lau_id').sum()\n",
    "if not 'lau_id' in sm.zones.columns:\n",
    "    sm.zones['lau_id'] = sm.zones['ARS'].apply(lambda l: int(str(l[0])[:-4]))\n",
    "sm.zones['is_urban'] = (sm.zones['urbanisation']==1) & (sm.zones['population']>100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f37179b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volumes for education\n",
    "# Emissions are people in education (school, apprenticeship, higher education)\n",
    "# Attractions are corresponding institutions\n",
    "emission = \\\n",
    "    {'higher_education':\n",
    "        sm.zones['lau_id'].map(\n",
    "            age_groups['18 bis unter 20 Jahre']\n",
    "            + age_groups['20 bis unter 25 Jahre']\n",
    "        ) * sm.zones['pop_share']\n",
    "        * sm.zones['is_urban'].map(lambda urban: params['generation']['students_per_18-25yo_urban']\n",
    "                                   if urban else params['generation']['students_per_18-25yo_non-urban']),\n",
    "    'school':\n",
    "        sm.zones['lau_id'].map(\n",
    "            age_groups['6 bis unter 10 Jahre']\n",
    "            + age_groups['10 bis unter 15 Jahre']\n",
    "            + age_groups['15 bis unter 18 Jahre']\n",
    "        ) * sm.zones['pop_share']\n",
    "        * sm.zones['is_urban'].map(lambda urban: params['generation']['pupils_per_6-18yo_urban']\n",
    "                                   if urban else params['generation']['pupils_per_6-18yo_non-urban']),\n",
    "    'employment':\n",
    "        sm.zones['lau_id'].map(\n",
    "            age_groups['18 bis unter 20 Jahre']\n",
    "        ) * sm.zones['pop_share']\n",
    "        * sm.zones['is_urban'].map(lambda urban: params['generation']['apprentices_per_18-20yo_urban']\n",
    "                                   if urban else params['generation']['apprentices_per_18-20yo_non-urban'])\n",
    "   }\n",
    "\n",
    "vol_df = volumes[['origin', 'destination']].copy()\n",
    "institutions = ['higher_education', 'school', 'employment']\n",
    "for institution in institutions:\n",
    "    days = params['generation']['edu_days_in_'+institution]\n",
    "    no_car_share = params['generation']['edu_share_without_car']\n",
    "    \n",
    "    # With car available\n",
    "    sm.zones['emission'] = emission[institution] * sm.zones['car_avail_hh'] * days * 2\n",
    "    sm.zones['attraction'] = sm.zones[institution] * sm.zones['car_avail_hh'] * days * 2\n",
    "    vol_df[institution+'_car'] = vol_df.merge(\n",
    "        od_volume_from_zones(sm.zones,\n",
    "                             get_deterrence('education_car',\n",
    "                                            params['distribution_exponent']['education_car']\n",
    "                                           )),\n",
    "        how='left', on=['origin', 'destination']\n",
    "    )['volume'].fillna(0)\n",
    "    \n",
    "    # Without car available\n",
    "    sm.zones['emission'] = emission[institution] * (1 - sm.zones['car_avail_hh']) * days * 2 * no_car_share\n",
    "    sm.zones['attraction'] = sm.zones[institution] * (1 - sm.zones['car_avail_hh']) * days * 2 * no_car_share\n",
    "    vol_df[institution+'_no_car'] = vol_df.merge(\n",
    "        od_volume_from_zones(sm.zones,\n",
    "                             get_deterrence('education_no_car',\n",
    "                                            params['distribution_exponent']['education_no_car']\n",
    "                                           )),\n",
    "        how='left', on=['origin', 'destination']\n",
    "    )['volume'].fillna(0)\n",
    "    \n",
    "# Sum up all these education groups\n",
    "volumes['education_car'] = vol_df[[i+'_car' for i in institutions]].sum(axis=1)\n",
    "volumes['education_no_car'] = vol_df[[i+'_no_car' for i in institutions]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6fd4c0c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>destination</th>\n",
       "      <th>accompany_car</th>\n",
       "      <th>accompany_no_car</th>\n",
       "      <th>buy/execute_car</th>\n",
       "      <th>buy/execute_no_car</th>\n",
       "      <th>leisure_car</th>\n",
       "      <th>leisure_no_car</th>\n",
       "      <th>business_car</th>\n",
       "      <th>education_no_car</th>\n",
       "      <th>commuting_car</th>\n",
       "      <th>education_car</th>\n",
       "      <th>commuting_no_car</th>\n",
       "      <th>business_no_car</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1093188</th>\n",
       "      <td>DE22C_2</td>\n",
       "      <td>DEA1F_5</td>\n",
       "      <td>0.007291</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>3.054860e-16</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>2.586243</td>\n",
       "      <td>0.004358</td>\n",
       "      <td>1.560596</td>\n",
       "      <td>5.918683e-207</td>\n",
       "      <td>1.583719e-91</td>\n",
       "      <td>2.585126e-207</td>\n",
       "      <td>8.206345e-146</td>\n",
       "      <td>0.073071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          origin destination  accompany_car  accompany_no_car  \\\n",
       "1093188  DE22C_2     DEA1F_5       0.007291          0.003571   \n",
       "\n",
       "         buy/execute_car  buy/execute_no_car  leisure_car  leisure_no_car  \\\n",
       "1093188     3.054860e-16            0.000001     2.586243        0.004358   \n",
       "\n",
       "         business_car  education_no_car  commuting_car  education_car  \\\n",
       "1093188      1.560596     5.918683e-207   1.583719e-91  2.585126e-207   \n",
       "\n",
       "         commuting_no_car  business_no_car  \n",
       "1093188     8.206345e-146         0.073071  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volumes.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "138df577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN\n",
    "volumes = volumes.loc[~volumes.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9d7c924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Million trips per day: 195.72639454341723\n"
     ]
    }
   ],
   "source": [
    "# check the sum (million trips per day)\n",
    "print('Million trips per day: {}'.format(volumes[segments].sum().sum() / 1e6 / 365))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1cec57",
   "metadata": {},
   "source": [
    "## Sparsify the OD set\n",
    "\n",
    "Reduce the number of OD pairs to a sample while keeping the number of trips constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da1f1565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only sample, if the parameter is specified\n",
    "# and there has been no sampling in previous modelling steps\n",
    "sample_size = params['general']['od_sparse_sample']\n",
    "if sample_size > 0 and len(volumes) > sample_size and not scenario.endswith('equilibrium'):\n",
    "    # Set a stable seed, generating the same OD set in every scenario run\n",
    "    np.random.seed(42)\n",
    "    # Choice probabilities of OD pairs weighted by trip volumes\n",
    "    # That ensures having the most important/intensive OD pairs in the sample\n",
    "    original_sum = volumes[segments].sum().sum()\n",
    "    od_probabilities = volumes[segments].sum(axis=1) / original_sum\n",
    "    sample = np.random.choice(a=volumes.index,\n",
    "                              size=sample_size,\n",
    "                              p=od_probabilities)\n",
    "    # Add a sample without volume weighting for the right distance distribution\n",
    "    # (high volumes are usually short-distance connections)\n",
    "    sample2 = np.random.choice(a=volumes.index, size=sample_size)\n",
    "    '''# Define distance classes to keep the segment-specific distribution\n",
    "    merged = pd.merge(volumes, distances.fillna(1000), how='left',\n",
    "                      left_on=['origin', 'destination'], right_index=True)\n",
    "    bins = list(range(0, 1011, 10))\n",
    "    merged['bin'] = pd.cut(merged['length'], bins=bins, labels=bins[1:-1])\n",
    "    for seg in segments:\n",
    "        # Reduce the volumes matrix\n",
    "        expansion = merged.groupby('bin')[seg].sum() / sample_size\n",
    "        sparse = pd.Series(sample).value_counts().rename(seg)\n",
    "        sparse = pd.merge(sparse, merged['bin'], how='left',\n",
    "                          left_index=True, right_index=True)\n",
    "        #volumes[seg] =  * expansion'''\n",
    "    volumes = volumes.loc[set(sample).union(set(sample2))]\n",
    "    volumes[segments] *= original_sum / volumes[segments].sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2853d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Million trips per day after sampling: 195.72639454341723\n"
     ]
    }
   ],
   "source": [
    "# Check the sum (million trips per day)\n",
    "print('Million trips per day after sampling: {}'.format(volumes[segments].sum().sum() / 1e6 / 365))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "774503d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of OD pairs: 4930600\n"
     ]
    }
   ],
   "source": [
    "volumes = volumes.loc[~volumes.isna().all(axis=1)]\n",
    "print('Number of OD pairs: {}'.format(len(volumes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e4c4cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e39601fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.293549330886528"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inter-zonal trips (billion per year)\n",
    "volumes.loc[volumes['origin']!=volumes['destination'], segments].sum().sum() / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28c3cca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "volumes: 100%|███████████████████████████████████████████████████████████████████████████| 9/9 [00:24<00:00,  2.67s/it]\n"
     ]
    }
   ],
   "source": [
    "# Save volumes table\n",
    "sm.volumes = volumes.reset_index(drop=True)\n",
    "sm.to_zippedpickles(model_path + 'de_volumes', only_attributes=['volumes'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
