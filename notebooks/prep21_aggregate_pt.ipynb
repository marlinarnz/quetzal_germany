{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys # for automation and parallelisation\n",
    "manual, scenario = (True, 'base') if 'ipykernel' in sys.argv[0] else (False, sys.argv[1])\n",
    "if manual:\n",
    "    %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely import geometry\n",
    "from geopy.distance import geodesic\n",
    "import shapely.speedups\n",
    "from tqdm import tqdm\n",
    "from quetzal.model import stepmodel\n",
    "from quetzal.engine import engine\n",
    "from quetzal.io import excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation of the transport network.\n",
    "## Saves aggregated bus and short-distance rail network with other PT modes.\n",
    "## Needs PT networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '../input/'\n",
    "output_path = '../output/'\n",
    "model_path = '../model/' + scenario + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load scenario parameters\n",
    "params = excel.read_var(file='../input/parameters.xls', scenario=scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading StepModel with PT networks...\n",
    "sm = stepmodel.read_json(model_path + 'de_pt_network_agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.nodes.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide nodes\n",
    "print(sm.nodes.shape)\n",
    "disagg_nodes = sm.nodes.loc[sm.nodes['route_type']=='bus']\n",
    "sm.nodes = sm.nodes.loc[sm.nodes['route_type']!='bus']\n",
    "print(disagg_nodes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide links\n",
    "print(sm.links.shape)\n",
    "disagg_links = sm.links.loc[sm.links['route_type']=='bus']\n",
    "sm.links = sm.links.loc[sm.links['route_type']!='bus']\n",
    "print(disagg_links.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trips\n",
    "len(disagg_links['trip_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find relevant trips\n",
    "\n",
    "Mark trips that are relevant for inter-zonal connectivity and drop the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find trips that are only within one zone\n",
    "node_dict = disagg_nodes['FID'].to_dict()\n",
    "disagg_links['a_zone'] = disagg_links['a'].map(node_dict)\n",
    "disagg_links['b_zone'] = disagg_links['b'].map(node_dict)\n",
    "relevant = disagg_links.groupby('trip_id').apply(\n",
    "    lambda t: (t['a_zone']!=t['b_zone']).any()).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_links = disagg_links.loc[disagg_links['trip_id'].map(relevant)]\n",
    "len(agg_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop trips with duplicate zone connections\n",
    "trip_zones = agg_links.groupby('trip_id').apply(\n",
    "    lambda t: tuple(set(t[['a_zone', 'b_zone']].stack()))).to_dict()\n",
    "agg_links['zones'] = agg_links['trip_id'].map(trip_zones)\n",
    "relevant2 = agg_links.groupby('zones').apply(\n",
    "    lambda g: g.groupby('trip_id').apply(lambda t: len(t)).idxmin()) # choose shortest connection\n",
    "agg_links = agg_links.loc[agg_links['trip_id'].isin(relevant2)]\n",
    "len(agg_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_links.drop(['a_zone', 'b_zone', 'zones'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build footpaths from long-distance links to short-distance\n",
    "sm.footpaths = pd.DataFrame()\n",
    "for o in sm.nodes['route_type'].unique():\n",
    "    for d in disagg_nodes['route_type'].unique():\n",
    "        if o != d:\n",
    "            ntlegs = engine.ntlegs_from_centroids_and_nodes(\n",
    "                sm.nodes.loc[sm.nodes['route_type']==o],\n",
    "                disagg_nodes.loc[disagg_nodes['route_type']==d],\n",
    "                short_leg_speed=params['pt_access']['speed_walk'],\n",
    "                long_leg_speed=params['pt_access']['speed_bicycle'],\n",
    "                threshold=params['pt_access']['catchment_radius_walk'],\n",
    "                n_neighbors=params['access-egress_links']['n_long-pt_short-pt'],\n",
    "                coordinates_unit=sm.coordinates_unit)\n",
    "            if o == 'air':\n",
    "                ntlegs = ntlegs.loc[ntlegs['distance']<=\n",
    "                                    params['access-egress_links']['walk_air_max_dist']\n",
    "                                    + params['clustering']['radius_'+d]/2]\n",
    "            else:\n",
    "                ntlegs = ntlegs.loc[ntlegs['distance']<=\n",
    "                                    params['access-egress_links']['walk_max_dist']\n",
    "                                    + params['clustering']['radius_'+o]/2\n",
    "                                    + params['clustering']['radius_'+d]/2]\n",
    "            sm.footpaths = pd.concat([sm.footpaths, ntlegs])\n",
    "len(sm.footpaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unused nodes\n",
    "agg_nodes = disagg_nodes.loc[list(agg_links[['a', 'b']].stack().unique())\n",
    "                            + [n for n in sm.footpaths['a'] if n.startswith('b_')]]\n",
    "agg_nodes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find trips that connect long-distance stops\n",
    "trip_set = set(disagg_links.loc[(disagg_links['a'].isin(sm.footpaths['a'])) |\n",
    "                                (disagg_links['b'].isin(sm.footpaths['a'])), 'trip_id'])\n",
    "# Drop trips that are already found above\n",
    "trip_set = trip_set.difference(set(agg_links['trip_id']))\n",
    "len(trip_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add these trips to agg_links\n",
    "agg_links = pd.concat([agg_links, disagg_links.loc[disagg_links['trip_id'].isin(trip_set)]])\n",
    "len(agg_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove unneccessary stops\n",
    "Intermediate stops without further inter-connection can be dropped. Each zone should have at least one stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count connectivity\n",
    "n_links_dict = agg_links[['a', 'b']].stack().value_counts().to_dict()\n",
    "n_connectors_dict = sm.footpaths[['a', 'b']].stack().value_counts().to_dict()\n",
    "agg_nodes['n_links'] = agg_nodes.index.map(n_links_dict)\n",
    "agg_nodes['n_connectors'] = agg_nodes.index.map(n_connectors_dict).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save which trip_id of a long-distance node each agg. node serves\n",
    "connectors = sm.footpaths.loc[sm.footpaths['direction']=='access']\n",
    "long_nodes = sm.nodes.loc[sm.nodes.index.isin(connectors['a'].unique())]\n",
    "long_trips = sm.links.loc[sm.links['a'].isin(long_nodes.index)\n",
    "                         ].groupby('a').agg({'trip_id': tuple}).to_dict()['trip_id']\n",
    "long_trips.update(sm.links.loc[sm.links['b'].isin(set(long_nodes.index) - set(long_trips.keys()))\n",
    "                              ].groupby('b').agg({'trip_id': tuple}).to_dict()['trip_id'])\n",
    "agg_nodes['trip_id'] = connectors.groupby('b').apply(\n",
    "    lambda g: g['a'].drop_duplicates(keep='first').map(long_trips).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also save which zone-connecting bus trips are served by each node\n",
    "agg_nodes['bus_trip'] = disagg_links.loc[(disagg_links['trip_id'].map(relevant))\n",
    "                                         & (disagg_links['trip_id'].isin(relevant2))\n",
    "                                        ].groupby('a').agg({'trip_id': tuple})['trip_id']\n",
    "len(agg_nodes.loc[agg_nodes['bus_trip'].notna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the most connected node for every trip_id\n",
    "# in agg_links and in long-distance trips that are connected\n",
    "def get_nodes(zone):\n",
    "    to_return = []\n",
    "    if len(zone.loc[zone['trip_id'].notna()]) > 0:\n",
    "        # Long-distance connector nodes\n",
    "        trips = set(zone.loc[zone['trip_id'].notna(), 'trip_id'].sum())\n",
    "        nodes = zone.loc[zone['trip_id'].notna()].sort_values('n_connectors', ascending=False)\n",
    "        served = set(nodes.iloc[0]['trip_id'])\n",
    "        i = 1\n",
    "        while trips - served != set():\n",
    "            served = served.union(nodes.iloc[i]['trip_id'])\n",
    "            i += 1\n",
    "        to_return.append(nodes.iloc[:i])\n",
    "    if len(zone.loc[zone['bus_trip'].notna()]) > 0:\n",
    "        # Short-distance trip nodes\n",
    "        trips = set(zone.loc[zone['bus_trip'].notna(), 'bus_trip'].sum())\n",
    "        nodes = zone.loc[zone['bus_trip'].notna()].sort_values('n_links', ascending=False)\n",
    "        served = set()\n",
    "        if len(to_return) > 0 and len(to_return[0].loc[to_return[0]['bus_trip'].notna()]) > 0:\n",
    "            served = set(to_return[0].loc[to_return[0]['bus_trip'].notna(), 'bus_trip'].sum())\n",
    "        j = 0\n",
    "        while trips - served != set():\n",
    "            served = served.union(nodes.iloc[j]['bus_trip'])\n",
    "            j += 1\n",
    "        to_return.append(nodes.iloc[:j])\n",
    "    if len(to_return) == 0:\n",
    "        return\n",
    "    else:\n",
    "        return pd.concat(to_return)\n",
    "agg_nodes = agg_nodes.groupby('FID').apply(get_nodes).drop_duplicates().reset_index(level='FID', drop=True)\n",
    "len(agg_nodes)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Get the nodes with the highest connectivity\n",
    "# for each zone\n",
    "'''def get_nodes(zone):\n",
    "    most_links = zone.sort_values('n_links').iloc[[0]]\n",
    "    most_conn = zone.loc[(zone['n_connectors']>0)&(zone['n_links']>=1)]\n",
    "    return pd.concat([most_links, most_conn])\n",
    "agg_nodes = agg_nodes.groupby('FID').apply(get_nodes).drop_duplicates().reset_index(level='FID', drop=True)'''"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Get the 10% percentile of most connected short-dist nodes\n",
    "'''cutoff = agg_nodes.sort_values('n_links').tail(int(len(disagg_nodes)/10))['n_links'].min()\n",
    "cutoff'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if manual: gpd.GeoDataFrame(agg_nodes).plot(markersize=.5, figsize=(16,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpd.GeoDataFrame(agg_nodes[list(sm.nodes.columns)]).to_file('../agg_nodes.geojson', driver=\"GeoJSON\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate links\n",
    "\n",
    "Aggregate those those trips with removed nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for aggregating links\n",
    "geo_dict = agg_nodes['geometry'].to_dict()\n",
    "def agg_trips(trip):\n",
    "    # Drop links with missing nodes\n",
    "    missing_nodes = list(set(trip[['a', 'b']].stack()).difference(set(agg_nodes.index)))\n",
    "    trip_agg = trip.loc[~((trip['a'].isin(missing_nodes)) & trip['b'].isin(missing_nodes))\n",
    "                       ].sort_values('link_sequence')\n",
    "    if len(trip_agg.index) == 0:\n",
    "        # Trip is fully irrelevant\n",
    "        return\n",
    "    \n",
    "    if len(missing_nodes)==0 and len(trip.index)==len(trip_agg.index):\n",
    "        # This trip is not affected\n",
    "        return trip\n",
    "    \n",
    "    # Repair link succession\n",
    "    ind = list(trip_agg.index)\n",
    "    for i in range(len(ind) - 1):\n",
    "        if trip_agg.loc[ind[i], 'b'] in missing_nodes:\n",
    "            trip_agg.loc[ind[i + 1], 'a'] = trip_agg.loc[ind[i], 'a']\n",
    "            trip_agg.drop(ind[i], inplace=True)\n",
    "            i = i + 1\n",
    "    \n",
    "    ind = list(trip_agg.index)\n",
    "    if len(trip_agg.index) > 0 and trip_agg.loc[ind[0], 'a'] in missing_nodes:\n",
    "        # Drop unused first link\n",
    "        trip_agg = trip_agg.iloc[1:]\n",
    "    if len(trip_agg.index) > 0 and trip_agg.loc[ind[-1], 'b'] in missing_nodes:\n",
    "        # Drop unused last link\n",
    "        trip_agg = trip_agg.iloc[:-1]\n",
    "    ind = list(trip_agg.index)\n",
    "    if len(ind) == 0:\n",
    "        return\n",
    "    \n",
    "    # Aggregate travel time\n",
    "    for i in range(len(ind) - 1):\n",
    "        try:\n",
    "            assert trip_agg.loc[ind[i], 'b'] == trip_agg.loc[ind[i+1], 'a'], \\\n",
    "                'broken sequence in trip {}: stop {} has no successor link'.format(\n",
    "                    trip_agg['trip_id'].unique()[0], trip_agg.loc[ind[i], 'b'])\n",
    "        except AssertionError:\n",
    "            # Drop this trip\n",
    "            return\n",
    "        if trip_agg.loc[ind[i + 1], 'link_sequence'] - trip_agg.loc[ind[i], 'link_sequence'] > 1:\n",
    "            trip_agg.loc[ind[i], 'time'] = trip.loc[ind[i]:ind[i+1], 'time'].sum() - \\\n",
    "                trip_agg.loc[ind[i+1], 'time'] # pandas slicing includes both boundaries\n",
    "    \n",
    "    # Reindex the sequence numbers\n",
    "    trip_agg['link_sequence'] = [i for i in range(1, len(trip_agg.index)+1)]\n",
    "    \n",
    "    # Build geometries\n",
    "    try:\n",
    "        trip_agg['geometry'] = [geometry.LineString([geo_dict[a], geo_dict[b]])\n",
    "                                for a,b in zip(trip_agg['a'], trip_agg['b'])]\n",
    "    except KeyError:\n",
    "        return\n",
    "    \n",
    "    return trip_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faster variant for using multiple cores\n",
    "#import multiprocessing as mp\n",
    "#with mp.Pool(processes=4) as p:\n",
    "#    agg_links = pd.concat(p.map(\n",
    "#        agg_trips, [g for _, g in agg_links.groupby('trip_id')]))\n",
    "agg_links = agg_links.groupby('trip_id').apply(agg_trips).reset_index(level=0, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Links with stops that should be dropped\n",
    "errors = agg_links.loc[~(agg_links['a'].isin(list(agg_nodes.index))) |\n",
    "    ~(agg_links['b'].isin(list(agg_nodes.index)))]\n",
    "print(len(errors))\n",
    "print(errors['link_sequence'].unique())\n",
    "print(errors['route_type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop these erronous trips\n",
    "agg_links = agg_links.loc[~agg_links['trip_id'].isin(list(agg_links.loc[errors.index, 'trip_id']))]\n",
    "agg_links.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop trips with different IDs but same stop sequences\n",
    "s = agg_links.groupby('trip_id').agg(tuple).drop_duplicates('a', keep='first')\n",
    "agg_links = agg_links.loc[agg_links['trip_id'].isin(s.index)]\n",
    "agg_links.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build footpaths\n",
    "\n",
    "In addition to those generated above, build footpaths between agg_nodes, between long-distance nodes (because they overlay each other), and between centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build footbaths between aggregated short-distance nodes\n",
    "for o in agg_nodes['route_type'].unique():\n",
    "    for d in agg_nodes['route_type'].unique():\n",
    "        if o != d:\n",
    "            ntlegs = engine.ntlegs_from_centroids_and_nodes(\n",
    "                agg_nodes.loc[agg_nodes['route_type']==o],\n",
    "                agg_nodes.loc[agg_nodes['route_type']==d],\n",
    "                short_leg_speed=params['pt_access']['speed_walk'],\n",
    "                long_leg_speed=params['pt_access']['speed_bicycle'],\n",
    "                threshold=params['pt_access']['catchment_radius_walk'],\n",
    "                n_neighbors=params['access-egress_links']['n_short-pt_short-pt'],\n",
    "                coordinates_unit=sm.coordinates_unit)\n",
    "            ntlegs = ntlegs.loc[ntlegs['distance']<=\n",
    "                                params['access-egress_links']['walk_max_dist']\n",
    "                                + params['clustering']['radius_'+d]/2]\n",
    "            sm.footpaths = pd.concat([sm.footpaths, ntlegs])\n",
    "len(sm.footpaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Between long-distance nodes\n",
    "for o in sm.nodes['route_type'].unique():\n",
    "    for d in sm.nodes['route_type'].unique():\n",
    "        if o != d:\n",
    "            ntlegs = engine.ntlegs_from_centroids_and_nodes(\n",
    "                sm.nodes.loc[sm.nodes['route_type']==o],\n",
    "                sm.nodes.loc[sm.nodes['route_type']==d],\n",
    "                short_leg_speed=params['pt_access']['speed_walk'],\n",
    "                long_leg_speed=params['pt_access']['speed_bicycle'],\n",
    "                threshold=params['pt_access']['catchment_radius_walk'],\n",
    "                n_neighbors=params['access-egress_links']['n_long-pt_long-pt'],\n",
    "                coordinates_unit=sm.coordinates_unit)\n",
    "            if o == 'air':\n",
    "                ntlegs = ntlegs.loc[ntlegs['distance']<=\n",
    "                                    params['access-egress_links']['walk_air_max_dist']\n",
    "                                    + params['clustering']['radius_'+d]/2]\n",
    "            else:\n",
    "                ntlegs = ntlegs.loc[ntlegs['distance']<=\n",
    "                                    params['access-egress_links']['walk_max_dist']\n",
    "                                    + params['clustering']['radius_'+o]/2\n",
    "                                    + params['clustering']['radius_'+d]/2]\n",
    "            sm.footpaths = pd.concat([sm.footpaths, ntlegs])\n",
    "sm.footpaths.drop_duplicates(['a', 'b'], inplace=True)\n",
    "len(sm.footpaths)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Generate footpaths between centroids\n",
    "'''ntlegs = engine.ntlegs_from_centroids_and_nodes(\n",
    "    sm.centroids,\n",
    "    sm.centroids,\n",
    "    short_leg_speed=params['pt_access']['speed_bicycle'],\n",
    "    long_leg_speed=params['pt_access']['speed_bicycle'],\n",
    "    threshold=params['pt_access']['catchment_radius_walk'],\n",
    "    n_neighbors=params['access-egress_links']['n_bicycle_between_zones'],\n",
    "    coordinates_unit=sm.coordinates_unit)\n",
    "ntlegs = ntlegs.loc[ntlegs['distance']<=\n",
    "                    params['access-egress_links']['bicycle_max_dist']]\n",
    "ntlegs = ntlegs.loc[ntlegs['distance']!=0]\n",
    "ntlegs.drop_duplicates(['direction', 'distance', 'time'], inplace=True)\n",
    "sm.footpaths = pd.concat([sm.footpaths, ntlegs])\n",
    "len(sm.footpaths)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindex\n",
    "sm.footpaths.drop_duplicates(['a', 'b'], inplace=True)\n",
    "sm.footpaths.reset_index(drop=True, inplace=True)\n",
    "sm.footpaths.index = 'foot_' + pd.Series(sm.footpaths.index).astype(str)\n",
    "sm.footpaths.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unneccessary columns\n",
    "cols = ['speed_factor', 'short_leg_speed', 'long_leg_speed', 'rank']\n",
    "sm.footpaths.drop(cols, axis=1, inplace=True, errors='ignore')\n",
    "sm.footpaths.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to centroids\n",
    "\n",
    "Build access/egress links to the most important stops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute controids\n",
    "sm.centroids = gpd.GeoDataFrame(sm.zones[['FID', 'NUTS_ID']],\n",
    "                                geometry=gpd.points_from_xy(sm.zones['lat'], sm.zones['lon'], crs=sm.epsg),\n",
    "                                crs=sm.epsg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the connectivity of start nodes in links table\n",
    "n_links_dict = pd.concat([sm.links[['a', 'b']], agg_links[['a', 'b']]]).stack().value_counts().to_dict()\n",
    "agg_links['n_links'] = agg_links['a'].map(n_links_dict)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Choose which nodes to connect\n",
    "'''def get_first_node(g): # Some nodes might not be in disagg_nodes\n",
    "    n = 0\n",
    "    while n < len(g):\n",
    "        if g['a'][n] in node_dict.keys():\n",
    "            break\n",
    "        else:\n",
    "            n += 1\n",
    "    return g['a'][n] if n < len(g) else g['b'][n-1]\n",
    "# Take one node per trip_id with the highest connectivity\n",
    "# Take only nodes with higher connectivity for short-distances\n",
    "nodes_short = agg_links.loc[agg_links['n_links']>2].sort_values(\n",
    "    'n_links').groupby('trip_id').apply(get_first_node)\n",
    "# Every node must exist in the nodes table\n",
    "assert len(set(nodes_short).difference(set(agg_nodes.index))) == 0\n",
    "len(set(nodes_short))'''"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Compute PT access and egress links for short-distance trips\n",
    "# Connects only one node within the corresponding zone\n",
    "'''node_dict = agg_nodes['FID'].to_dict()\n",
    "type_dict = agg_nodes.loc[nodes_short, 'route_type'].to_dict()\n",
    "nodes_short = list(set(nodes_short))\n",
    "access = gpd.GeoDataFrame(\n",
    "    data={'a': [node_dict[n] for n in nodes_short], # centroid FID\n",
    "          'b': nodes_short,\n",
    "          'route_type': [type_dict[n] for n in nodes_short],\n",
    "          'direction': ['access']*len(nodes_short)},\n",
    "    geometry=[geometry.LineString([sm.centroids.loc[node_dict[n], 'geometry'].coords[0],\n",
    "                                   agg_nodes.loc[n, 'geometry'].coords[0]])\n",
    "              for n in nodes_short],\n",
    "    crs=sm.epsg)\n",
    "egress = gpd.GeoDataFrame( # turn it around\n",
    "    data={'a': list(access['b']),\n",
    "          'b': list(access['a']),\n",
    "          'route_type': [type_dict[n] for n in nodes_short],\n",
    "          'direction': ['eggress']*len(nodes_short)}, # name in quetzal\n",
    "    geometry=[geometry.LineString([l.coords[-1], l.coords[0]]) for l in list(access['geometry'])],\n",
    "    crs=sm.epsg)\n",
    "sm.zone_to_transit = pd.concat([access, egress]).reset_index(drop=True)\n",
    "len(sm.zone_to_transit)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute PT access and egress links for short-distance trips\n",
    "# Connects only nodes within the corresponding zone\n",
    "sm.zone_to_transit = pd.DataFrame()\n",
    "for z in tqdm(sm.centroids['FID'].unique()):\n",
    "    for t in agg_nodes['route_type'].unique():\n",
    "        nodes = agg_nodes.loc[(agg_nodes['route_type']==t) & (agg_nodes['FID']==z)]\n",
    "        if len(nodes) > 0:\n",
    "            ntlegs = engine.ntlegs_from_centroids_and_nodes(\n",
    "                sm.centroids.loc[sm.centroids['FID']==z],\n",
    "                nodes,\n",
    "                short_leg_speed=params['pt_access']['speed_walk'],\n",
    "                long_leg_speed=params['pt_access']['speed_car'], # Take the car for longer trips\n",
    "                threshold=params['pt_access']['catchment_radius_walk'],\n",
    "                n_neighbors=min([len(nodes), 20]),\n",
    "                coordinates_unit=sm.coordinates_unit)\n",
    "            # Cut off long links\n",
    "            ntlegs = ntlegs.loc[ntlegs['distance']<=\n",
    "                                params['access-egress_links']['pt_max_dist']]\n",
    "            ntlegs['route_type'] = t\n",
    "            # Merge\n",
    "            sm.zone_to_transit = pd.concat([sm.zone_to_transit, ntlegs])\n",
    "sm.zone_to_transit.reset_index(drop=True, inplace=True)\n",
    "len(sm.zone_to_transit.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute PT access and egress links for short-distance trips\n",
    "# Connect zones without own nodes to one node in the corresponding NUTS zone\n",
    "missing_zones = list(set(sm.centroids.index)\n",
    "                     - set(sm.zone_to_transit.loc[sm.zone_to_transit['direction']=='access', 'a']))\n",
    "for z in tqdm(missing_zones):\n",
    "    for t in agg_nodes['route_type'].unique():\n",
    "        nodes = agg_nodes.loc[(agg_nodes['route_type']==t) & (agg_nodes['FID'].str[:5]==z)]\n",
    "        if len(nodes) > 0:\n",
    "            ntlegs = engine.ntlegs_from_centroids_and_nodes(\n",
    "                sm.centroids.loc[sm.centroids['FID']==z],\n",
    "                nodes,\n",
    "                short_leg_speed=params['pt_access']['speed_walk'],\n",
    "                long_leg_speed=params['pt_access']['speed_car'], # Take the car for longer trips\n",
    "                threshold=params['pt_access']['catchment_radius_walk'],\n",
    "                n_neighbors=1,\n",
    "                coordinates_unit=sm.coordinates_unit)\n",
    "            # Cut off long links\n",
    "            ntlegs = ntlegs.loc[ntlegs['distance']<=\n",
    "                                params['access-egress_links']['pt_max_dist']]\n",
    "            ntlegs['route_type'] = t\n",
    "            # Merge\n",
    "            sm.zone_to_transit = pd.concat([sm.zone_to_transit, ntlegs])\n",
    "sm.zone_to_transit.reset_index(drop=True, inplace=True)\n",
    "len(sm.zone_to_transit.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute PT access and egress links for long-distance trips\n",
    "# only within the corresponding zone\n",
    "for z in tqdm(sm.centroids.index):\n",
    "    for t in sm.links['route_type'].unique():\n",
    "        nodes = sm.nodes.loc[(sm.nodes['route_type']==t) & (sm.nodes['FID']==z)]\n",
    "        if len(nodes) > 0:\n",
    "            ntlegs = engine.ntlegs_from_centroids_and_nodes(\n",
    "                sm.centroids.loc[[z]],\n",
    "                nodes,\n",
    "                short_leg_speed=params['pt_access']['speed_walk'],\n",
    "                long_leg_speed=params['pt_access']['speed_car'], # Take the car for longer trips\n",
    "                threshold=params['pt_access']['catchment_radius_walk'],\n",
    "                n_neighbors=len(nodes),\n",
    "                coordinates_unit=sm.coordinates_unit)\n",
    "            # Cut off long links\n",
    "            ntlegs = ntlegs.loc[ntlegs['distance']<=\n",
    "                                params['access-egress_links']['pt_max_dist']]\n",
    "            ntlegs['route_type'] = t\n",
    "            # Merge\n",
    "            sm.zone_to_transit = pd.concat([sm.zone_to_transit, ntlegs])\n",
    "        #else:\n",
    "        #    print('No {} stop in zone {}'.format(t,z))\n",
    "sm.zone_to_transit.reset_index(drop=True, inplace=True)\n",
    "len(sm.zone_to_transit.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare links for filtering\n",
    "sm.zone_to_transit['distance'] = sm.zone_to_transit['geometry'].apply(lambda l: l.length)\n",
    "access = sm.zone_to_transit.loc[sm.zone_to_transit['direction']=='access']\n",
    "access['n_links'] = access['b'].map(n_links_dict)\n",
    "egress = sm.zone_to_transit.loc[sm.zone_to_transit['direction']=='eggress']\n",
    "egress['n_links'] = egress['a'].map(n_links_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter: search for highest connectivity and shortest links per route_type\n",
    "access = pd.concat([\n",
    "    access.sort_values('n_links', ascending=False).groupby(['a', 'route_type']).nth(\n",
    "        list(range(params['access-egress_links']['keep_n_highest_connectivity']))\n",
    "    ).reset_index(),\n",
    "    access.sort_values('distance').groupby(['a', 'route_type']).nth(\n",
    "        list(range(params['access-egress_links']['keep_n_closest']))\n",
    "    ).reset_index()]\n",
    ").drop_duplicates(['a', 'b'])\n",
    "egress = pd.concat([\n",
    "    egress.sort_values('n_links', ascending=False).groupby(['b', 'route_type']).nth(\n",
    "        list(range(params['access-egress_links']['keep_n_highest_connectivity']))\n",
    "    ).reset_index(),\n",
    "    egress.sort_values('distance').groupby(['b', 'route_type']).nth(\n",
    "        list(range(params['access-egress_links']['keep_n_closest']))\n",
    "    ).reset_index()]\n",
    ").drop_duplicates(['a', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all links but the shortest for nodes in zones different\n",
    "# to the centroid\n",
    "node_dict = agg_nodes['FID'].to_dict()\n",
    "outer = access.loc[(access['a']!=access['b'].map(node_dict))\n",
    "                   & (access['route_type'].isin(agg_nodes['route_type'].unique()))].copy()\n",
    "access.drop(outer.index, inplace=True)\n",
    "access = pd.concat([access, outer.sort_values('distance').groupby('a').first().reset_index()])\n",
    "outer = egress.loc[(egress['b']!=egress['a'].map(node_dict))\n",
    "                   & (egress['route_type'].isin(agg_nodes['route_type'].unique()))].copy()\n",
    "egress.drop(outer.index, inplace=True)\n",
    "egress = pd.concat([egress, outer.sort_values('distance').groupby('b').first().reset_index()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.zone_to_transit = pd.concat([access, egress]).reset_index(drop=True)\n",
    "sm.zone_to_transit.drop('n_links', axis=1, inplace=True)\n",
    "sm.zone_to_transit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every zone should have an access and an egress link to PT\n",
    "try:\n",
    "    assert sm.zones['FID'].isin(list(sm.zone_to_transit['a'])).all()\n",
    "except AssertionError:\n",
    "    print(sm.zones.loc[~sm.zones['FID'].isin(list(sm.zone_to_transit['a']))].index)\n",
    "try:\n",
    "    assert sm.zones['FID'].isin(list(sm.zone_to_transit['b'])).all()\n",
    "except AssertionError:\n",
    "    print(sm.zones.loc[~sm.zones['FID'].isin(list(sm.zone_to_transit['b']))].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parametrise access and egress  links\n",
    "\n",
    "Add distance, speed and time. Average distances by zone and mode should have been calculated based on census data before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unneccessary columns\n",
    "cols = ['speed_factor', 'short_leg_speed', 'long_leg_speed', 'rank']\n",
    "sm.zone_to_transit.drop(cols, axis=1, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load distances to PT stops from census data\n",
    "clusters = pd.read_csv(input_path + 'spatial_census_refined.csv')\n",
    "#clusters.set_index('Unnamed: 0', inplace=True)\n",
    "dist_col = 'weighted_dist'\n",
    "mean_dist_col = 'mean_weighted_dist'\n",
    "cent_col = 'cluster_center'\n",
    "#pop_col = 'population'\n",
    "node_col = 'node_id'\n",
    "# Create a zone - distance - type dict\n",
    "# Take the mean weighted distance\n",
    "zone = 'FID' if 'FID' in clusters.columns else 'NUTS_ID'\n",
    "zone_type_dist = clusters.groupby([zone, 'route_type']).agg(\n",
    "    {mean_dist_col: 'mean'}).to_dict()[mean_dist_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust distances\n",
    "access = sm.zone_to_transit.loc[sm.zone_to_transit['direction']=='access']\n",
    "egress = sm.zone_to_transit.loc[sm.zone_to_transit['direction']=='eggress']\n",
    "access['distance'] = [zone_type_dist[(z, t)] if (z, t) in zone_type_dist.keys() else np.nan\n",
    "                      for z,t in zip(access['a'], access['route_type'])]\n",
    "egress['distance'] = [zone_type_dist[(z, t)] if (z, t) in zone_type_dist.keys() else np.nan\n",
    "                      for z,t in zip(egress['b'], egress['route_type'])]\n",
    "sm.zone_to_transit = pd.concat([access, egress])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance distribution among access/egress links\n",
    "if manual: sm.zone_to_transit['distance'].hist(bins=20, figsize=(4,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sm.zone_to_transit.loc[sm.zone_to_transit['distance'].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a distance for zones which have no bus stop\n",
    "mask = (sm.zone_to_transit['distance'].isna()) & (sm.zone_to_transit['route_type']=='bus')\n",
    "sm.zone_to_transit.loc[mask, 'distance'] = clusters.loc[clusters['route_type']=='bus', mean_dist_col].max()\n",
    "# Number of links that still have no distance\n",
    "len(sm.zone_to_transit.loc[sm.zone_to_transit['distance'].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connectors to/from long-distance nodes in the same zone\n",
    "# Assign average distance of the corresponding urbanisation degree\n",
    "node_dict = sm.nodes['FID'].to_dict()\n",
    "urban_dict = sm.zones['urbanisation'].to_dict()\n",
    "clusters['u'] = clusters[zone].map(urban_dict)\n",
    "mean_distances = clusters.groupby(['u', 'route_type'])[mean_dist_col].mean().to_dict()\n",
    "mask = (sm.zone_to_transit['distance'].isna()) \\\n",
    "    & (((sm.zone_to_transit['direction']=='access')\n",
    "        & (sm.zone_to_transit['a']==sm.zone_to_transit['b'].map(node_dict)))\n",
    "       | ((sm.zone_to_transit['direction']=='eggress')\n",
    "          & (sm.zone_to_transit['b']==sm.zone_to_transit['a'].map(node_dict))))\n",
    "sm.zone_to_transit.loc[sm.zone_to_transit['direction']=='access', 'u'] = \\\n",
    "    sm.zone_to_transit.loc[sm.zone_to_transit['direction']=='access', 'a'].map(urban_dict)\n",
    "sm.zone_to_transit.loc[sm.zone_to_transit['direction']=='eggress', 'u'] = \\\n",
    "    sm.zone_to_transit.loc[sm.zone_to_transit['direction']=='eggress', 'b'].map(urban_dict)\n",
    "sm.zone_to_transit.loc[mask, 'distance'] = [mean_distances[(u, t)] for u,t in zip(\n",
    "    sm.zone_to_transit.loc[mask, 'u'], sm.zone_to_transit.loc[mask, 'route_type'])]\n",
    "len(sm.zone_to_transit.loc[sm.zone_to_transit['distance'].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connectors to/from long-distance nodes in other zones\n",
    "# Drop NaN, because they cause that people don't take short-distance PT,\n",
    "# but walk over to the next airport and walk to the neighboring centroid\n",
    "sm.zone_to_transit = sm.zone_to_transit.loc[sm.zone_to_transit['distance'].notna()]\n",
    "sm.zone_to_transit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct speeds based on access/egress modes\n",
    "speeds = {'walk': params['pt_access']['speed_walk'],\n",
    "          'bicycle': params['pt_access']['speed_bicycle'],\n",
    "          'car': params['pt_access']['speed_car']} # km/h\n",
    "sm.zone_to_transit['speed'] = [sum([speed * params['pt_access']['urban'+str(int(u))+'_'+mode+'_share'\n",
    "                                                               ] for mode, speed in speeds.items()])\n",
    "                               for u in sm.zone_to_transit['u']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speed distribution among access/egress links\n",
    "if manual: sm.zone_to_transit['speed'].hist(bins=20, figsize=(4,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alter time of PT legs\n",
    "sm.zone_to_transit['time'] = sm.zone_to_transit['distance'] / \\\n",
    "    sm.zone_to_transit['speed'] * 3.6 # in s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ditch all legs which take too long\n",
    "sm.zone_to_transit = sm.zone_to_transit.loc[sm.zone_to_transit['time']<2*3600]\n",
    "len(sm.zone_to_transit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every zone should have an access and an egress link to PT\n",
    "try:\n",
    "    assert sm.zones['FID'].isin(list(sm.zone_to_transit['a'])).all()\n",
    "except AssertionError:\n",
    "    print(sm.zones.loc[~sm.zones['FID'].isin(list(sm.zone_to_transit['a']))].index)\n",
    "try:\n",
    "    assert sm.zones['FID'].isin(list(sm.zone_to_transit['b'])).all()\n",
    "except AssertionError:\n",
    "    print(sm.zones.loc[~sm.zones['FID'].isin(list(sm.zone_to_transit['b']))].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time distribution of access/egress links\n",
    "if manual: (sm.zone_to_transit['time']/3600).hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.zone_to_transit.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge aggregated links and nodes with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-add links to model\n",
    "sm.links = pd.concat([sm.links, agg_links[list(sm.links.columns)]])\n",
    "sm.links.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-add nodes to the model\n",
    "sm.nodes = pd.concat([sm.nodes, agg_nodes[list(sm.nodes.columns)]])\n",
    "sm.nodes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sm.integrity_test_nodeset_consistency()\n",
    "except AssertionError:\n",
    "    print('Number of orphan nodes: {}'.format(\n",
    "        len(sm.orphan_nodes)))\n",
    "    print('Number of missing nodes: {}'.format(\n",
    "        len(sm.missing_nodes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sm.missing_nodes) == 0\n",
    "if len(sm.orphan_nodes) > 0:\n",
    "    sm.nodes = sm.nodes.drop(sm.orphan_nodes)\n",
    "    sm.nodes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.links.loc[sm.links['route_type']=='rail_short'].sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop footpaths to nowhere\n",
    "sm.footpaths = sm.footpaths.loc[(sm.footpaths['a'].isin(sm.nodes.index))\n",
    "                                & (sm.footpaths['b'].isin(sm.nodes.index))]\n",
    "len(sm.footpaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model\n",
    "And reduce the file size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast columns to int\n",
    "cols = ['time', 'link_sequence', 'headway']\n",
    "sm.links[cols] = sm.links[cols].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split links in graph and auxiliary information\n",
    "# for file sizes being compatible with github's size limit\n",
    "cols = ['a', 'b', 'link_sequence', 'route_id', 'time', 'trip_id', 'headway', 'route_type_disagg']\n",
    "auxiliary = sm.links[cols]\n",
    "sm.links.drop(cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model...\n",
    "sm.to_json(model_path + 'de_pt_network_agg',\n",
    "           only_attributes=['zones', 'links', 'nodes', 'pt_route_types'],\n",
    "           encoding='utf-8')\n",
    "sm.to_json(model_path + 'de_pt_network_ancillary',\n",
    "           only_attributes=['agencies', 'pt_routes'],\n",
    "           encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save auxiliary information seperately\n",
    "auxiliary['index'] = auxiliary.index\n",
    "auxiliary.reset_index(drop=True, inplace=True)\n",
    "auxiliary.to_json(model_path + 'de_pt_network_agg/links_quetzaldata.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save reduced access/egress links\n",
    "sm.to_json(model_path + 'de_pt_access_egress', only_attributes=[\n",
    "    'centroids', 'footpaths', 'zone_to_transit'], encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
