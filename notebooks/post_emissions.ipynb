{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys # for automation and parallelisation\n",
    "manual, scenario = (True, 'base') if 'ipykernel' in sys.argv[0] else (False, sys.argv[1])\n",
    "if manual:\n",
    "    %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "from tqdm import tqdm\n",
    "from quetzal.model import stepmodel\n",
    "from syspy.skims import skims\n",
    "from quetzal.io import excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emissions modelling\n",
    "## Saves emissions from passenger transport\n",
    "## Needs inner- and intra-zonal passenger kilometer by mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '../input_static/'\n",
    "output_path = '../output/' + scenario + '/'\n",
    "model_path = '../model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load scenario parameters\n",
    "params = excel.read_var(file='../input/parameters.xls', scenario=scenario)\n",
    "segments = [s.strip() for s in params['general']['demand_segments'].split(';')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = stepmodel.read_zippedpickles(model_path + scenario + '/' + 'de_assignment')\n",
    "try:\n",
    "    z = stepmodel.read_json(model_path + scenario + '/' + 'de_zones')\n",
    "except FileNotFoundError:\n",
    "    z = stepmodel.read_json(model_path + 'base/' + 'de_zones')\n",
    "sm.zones = z.zones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Road link vkm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter unused road links\n",
    "sm.road_links = sm.road_links.loc[(sm.road_links[\"volume\"].notna())\n",
    "                                  & (sm.road_links[\"volume\"]>0)]\n",
    "len(sm.road_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate vehicle kilometers by demand segment\n",
    "# As done in model_assignment_inner-zone\n",
    "occ_dict = params['car_occ'] # MiD2017 data, see cal10\n",
    "sm.road_links['vkm'] = sm.road_links[\"volume\"] \\\n",
    "    * sm.road_links['length']/1000 / occ_dict['all']\n",
    "#for seg in segments:\n",
    "#    sm.road_links['vkm'] += sm.road_links[(seg, 'car')] \\\n",
    "#        * sm.road_links['length']/1000 / occ_dict[seg]#[0]]\n",
    "sm.road_links['vkm'] = sm.road_links['vkm'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum up vkm by region and speed limit\n",
    "sm.road_links['NUTS1'] = sm.road_links['NUTS3'].str[:3]\n",
    "inter_car = sm.road_links.groupby(['NUTS1', 'maxspeed']).agg({'vkm': 'sum'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PT link mapping and pkm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unused PT links\n",
    "sm.links = sm.links.loc[(sm.links['volume'].notna()) & (sm.links['volume']>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate length for PT links if not done yet\n",
    "if 'length' not in sm.links.columns:\n",
    "    sm.links['length'] = skims.distance_from_geometry(\n",
    "        sm.links['geometry']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emissions from PT are considered in the service's origin\n",
    "sm.links['NUTS1'] = sm.links['a'].map(sm.nodes['FID'].str[:3])\n",
    "sm.links['pkm'] = sm.links['length']/1000 * sm.links['volume']\n",
    "inter_pt = sm.links.groupby(['NUTS1', 'route_type']).agg({'pkm': 'sum'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge with inner-zonal traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results of inner-zonal traffic\n",
    "inner = pd.read_excel(output_path + 'inner_zone.xlsx', sheet_name='agg', index_col=[0,1])\n",
    "inner = inner.rename(index={'rail': 'rail_short'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine results\n",
    "sm.road_links['pkm'] = sm.road_links[\"volume\"] * sm.road_links['length']/1000\n",
    "sm.road_links['route_type'] = 'car'\n",
    "all_pkm = pd.concat([sm.road_links.groupby(['NUTS1', 'route_type']).agg({'pkm': 'sum'}), inter_pt])\n",
    "inner.index.rename(['NUTS1', 'route_type'], inplace=True)\n",
    "all_pkm = all_pkm.merge(inner['pkm'], how='outer', left_index=True,\n",
    "                        right_index=True, suffixes=['_inter', '_inner']).fillna(0)\n",
    "all_pkm['pkm'] = all_pkm['pkm_inter'] + all_pkm['pkm_inner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pkm['pkm'].unstack().sum(axis=0).plot.pie(subplots=True, title='Modal split in pkm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mode shares in percent\")\n",
    "mode_agg = {'tram': 'bus', 'subway': 'bus', 'ferry': 'bus', 'funicular': 'bus', 'coach': 'bus',\n",
    "            'rail_long': 'rail', 'rail_short': 'rail'}\n",
    "total = all_pkm['pkm'].sum()\n",
    "pkm_shares_percent = all_pkm.rename(index=mode_agg).groupby(level=1).agg({'pkm': 'sum'})/total*100 \n",
    "print(pkm_shares_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkm_total = pd.DataFrame(data = {\"bn. pkm\" : [round(total/1e9,5)]}, index=['total'])\n",
    "print('Total traffic (billion pkm):')\n",
    "print(pkm_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mode shares in total (billion pkm)\")\n",
    "pkm_shares_total = all_pkm.rename(index=mode_agg).groupby(level=1).agg({'pkm': 'sum'})/1e9\n",
    "pkm_shares_total.columns = ['bn. pkm']\n",
    "pkm_shares_total = pd.concat([pkm_shares_total, pkm_total])\n",
    "print(pkm_shares_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge car vkm\n",
    "car_vkm = inner.xs('car', level=1)[['vkm']].merge(\n",
    "    inter_car.groupby(level=0).sum()['vkm'], how='outer', left_index=True,\n",
    "    right_index=True, suffixes=['_inner', '_inter']).fillna(0)\n",
    "car_vkm['vkm'] = car_vkm['vkm_inter'] + car_vkm['vkm_inner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average vkm per year by roughly 46 Mio. cars in Germany 2017 (GENESIS database)')\n",
    "car_vkm_total = pd.DataFrame(data = {\"vkm\" : [car_vkm['vkm'].sum() / params['vehicles']['car']]}, index=['total'])\n",
    "print(car_vkm_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('thereof inner model zones')\n",
    "car_vkm_inner = pd.DataFrame(data = {\"vkm\" : [car_vkm['vkm_inner'].sum() / params['vehicles']['car']]}, index=['inner'])\n",
    "print(car_vkm_inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('thereof inter model zones')\n",
    "car_vkm_inter = pd.DataFrame(data = {\"vkm\" : [car_vkm['vkm_inter'].sum() / params['vehicles']['car']]}, index=['inner'])\n",
    "print(car_vkm_inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Official values for 2017 from TREMOD')\n",
    "car_vkm_off = pd.DataFrame(data = {\"vkm\" : [round(656800000000 / params['vehicles']['car'],6)]}, index=['official'])\n",
    "print(car_vkm_off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average car vkm per year')\n",
    "vkm_car_all = pd.concat([car_vkm_total, car_vkm_inner, car_vkm_inter, car_vkm_off])\n",
    "print(vkm_car_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate PT vehicle loads\n",
    "\n",
    "While vkm of car traffic are straight forward (using average occupancies and pkm), PT vkm strongly depend on the transport supply system. They can be modelled using average occupancy factors of PT/sharing vehicles (as for private cars), or depend on vehicle circulations that are statically defined in schedules.\n",
    "\n",
    "Absolute road PT vkm values can be retrieved from BMVI 2018, \"Verkehr in Zahlen 2018/19\", p. 81. Rail vkm can be generated endogenously using GTFS feeds.\n",
    "\n",
    "Scientific thoughts regarding a thorough and computational efficient method can be found here: https://doi.org/10.1016/j.procs.2021.03.022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use PT load factors calculated from 2018 values.\n",
    "# They are already included into below emission factors per pkm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate emissions from vkm\n",
    "\n",
    "Reference emissions for 2019 (no change compared to 2017) from passenger traffic in Germany are 164 Mio. tCO2eq * (60.8(car)+1.4(air)+0.3(rail)+XXX(bus)=65)% = 107 Mio. tCO2eq\n",
    "\n",
    "Source: Bundesministerium für Umwelt, Naturschutz und nukleare Sicherheit (2021): Klimaschutz in Zahlen - Fakten, Trends und Impulse deutscher Klimapolitik Ausgabe 2021, p. 36\n",
    "\n",
    "Data sources for emission factors in this model are\n",
    "* vkm car: TREMOD (Transport Emission Model; underlying values come from HBEFA (Handbuch Emissionsfaktoren)): \"Aktualisierung der Modelle TREMOD/TREMOD-MM für die Emissionsberichterstattung 2020 (Berichtsperiode 1990-2018)\", 2020\n",
    "* pkm PT: UBA (Umweltbundesamt): \"Vergleich der durchschnittlichen Emissionen einzelner Verkehrsmittel im Personenverkehr in Deutschland\", 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_dict = params['emissions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cars\n",
    "# In 2017, there were 66% petrol and 33% diesel cars, rest is mainly LPG (TREMOD, p. 43)\n",
    "# Take REAL average emissions in gCO2eq/km (TREMOD, p. 54)\n",
    "car_em = 0.66*173.6 + 0.33*187.6 + 0.01*104\n",
    "inter_car['tCO2eq'] = inter_car['vkm'] * em_dict['car'] / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PT (UBA)\n",
    "inter_pt['tCO2eq'] = inter_pt['pkm'] * inter_pt.index.get_level_values(1).map(em_dict) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner-zonal\n",
    "mask = (inner.index.get_level_values(1)=='car')\n",
    "inner.loc[mask,'tCO2eq'] = inner.loc[mask,'vkm'] * \\\n",
    "    inner.loc[mask].index.get_level_values(1).map(em_dict) / 1e6\n",
    "inner.loc[~mask,'tCO2eq'] = inner.loc[~mask,'pkm'] * \\\n",
    "    inner.loc[~mask].index.get_level_values(1).map(em_dict) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Local transport emissions (mio. tonnes):')\n",
    "emiss_short = inner.groupby('route_type').agg({'tCO2eq': 'sum'}) / 1e6\n",
    "emiss_short.columns = ['mio tCO2eq']\n",
    "print(emiss_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CAR: Long-distance transport emissions (mio. tonnes): \")\n",
    "emiss_car_long = pd.DataFrame(data = {\"mio tCO2eq\" : [inter_car['tCO2eq'].sum()/1e6]}, index = ['car_long'])\n",
    "print(emiss_car_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PT: Long-distance transport emissions (mio. tonnes): \")\n",
    "emiss_pt_long = inter_pt.groupby('route_type').agg({'tCO2eq': 'sum'}) / 1e6\n",
    "emiss_pt_long.columns = ['mio tCO2eq']\n",
    "print(emiss_pt_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Long-distance transport emissions (mio. tonnes): \")\n",
    "emiss_long = pd.concat([emiss_pt_long, emiss_car_long])\n",
    "print(emiss_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop speeds in car km\n",
    "inter_car = inter_car.groupby(level=0).sum()\n",
    "inter_car['route_type'] = 'car'\n",
    "inter_car.set_index('route_type', append=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge emissions together\n",
    "all_em = pd.concat([inter_pt[['tCO2eq']], inter_car[['tCO2eq']], inner[['tCO2eq']]])\n",
    "all_em = all_em.groupby(level=[0,1]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emissions by region and mode\n",
    "all_em.unstack().plot.bar(subplots=False, figsize=(16,4), width=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save\n",
    "Create one ecxel output with pkm, emissions, time and cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load inter-zonal aggregated results\n",
    "inter = pd.read_excel(output_path + 'inter_zone.xlsx',\n",
    "                      sheet_name='od', index_col=[0,1,2])\n",
    "# Get time and price weighted averages by origin and mode\n",
    "weighted_av = lambda x: np.average(x, weights=inter.loc[x.index, 'volume'])\n",
    "inter = inter.groupby(level=[0,2]).agg(\n",
    "    volume=('volume', 'sum'),\n",
    "    time=('time', weighted_av),\n",
    "    length=('length', weighted_av))\n",
    "inter.index.rename(['NUTS1', 'route_type'], inplace=True)\n",
    "# Sums\n",
    "for col in ['time', 'length']:\n",
    "    inter[col] = inter[col] * inter['volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge times\n",
    "time = inter[['time']].merge(\n",
    "    (inner['time']*inner['volumes']).rename('time'), how='outer',\n",
    "    left_index=True, right_index=True, suffixes=['_inter', '_inner']).fillna(0)\n",
    "time['time'] = time['time_inter'] + time['time_inner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average car operating hours per day per car\n",
    "time.xs('car', level=1)['time'].sum() / params['vehicles']['car'] / 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge prices\n",
    "if 'price' in inter.columns:\n",
    "    price = inter[['price']].merge(\n",
    "        (inner['price']*inner['volumes']).rename('price'), how='outer',\n",
    "        left_index=True, right_index=True, suffixes=['_inter', '_inner']).fillna(0)\n",
    "    price['price'] = price['price_inter'] + price['price_inner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data disaggregated by regions to excel\n",
    "with pd.ExcelWriter(output_path + 'results_agg.xlsx') as writer:  \n",
    "    all_pkm.to_excel(writer, sheet_name='pkm')\n",
    "    car_vkm.to_excel(writer, sheet_name='car_vkm')\n",
    "    all_em.to_excel(writer, sheet_name='emissions')\n",
    "    time.to_excel(writer, sheet_name='time')\n",
    "    if 'price' in inter.columns: price.to_excel(writer, sheet_name='price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save total values to excel\n",
    "with pd.ExcelWriter(output_path + 'results_total.xlsx') as writer:  \n",
    "    pkm_shares_percent.to_excel(writer, sheet_name='pkm_shares_percent')\n",
    "    pkm_shares_total.to_excel(writer, sheet_name='pkm_shares_total')\n",
    "    vkm_car_all.to_excel(writer, sheet_name='average_vkm_car_yr')\n",
    "    emiss_short.to_excel(writer, sheet_name='emissions_local')\n",
    "    emiss_long.to_excel(writer, sheet_name='emissions_long')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save disaggregated results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inter-zonal pkm\n",
    "inter_car = sm.road_links.groupby('NUTS3').agg({\"pkm\": 'sum'})\n",
    "sm.links['NUTS3'] = sm.links['a'].map(sm.nodes['FID'].str[:5])\n",
    "inter_pt = sm.links.groupby(['NUTS3', 'route_type']).agg({'pkm': 'sum'})\n",
    "inter_car['route_type'] = 'car'\n",
    "inter = pd.concat([inter_car.groupby(['NUTS3', 'route_type']).agg({'pkm': 'sum'}), inter_pt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load inner-zonal disaggregated pkm\n",
    "inner = pd.read_csv(output_path + 'inner_zone_pkm.csv', header=[0,1], index_col=0)\n",
    "inner = inner.stack('mode').reset_index().replace({'rail': 'rail_short', 'non-motorised': 'walk'})\n",
    "inner['origin'] = inner['origin'].str[:5] # NUTS3\n",
    "inner = inner.groupby(['origin', 'mode']).sum().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All together\n",
    "inter.index.names = inner.index.names\n",
    "all_pkm = pd.merge(inner.rename('pkm'), inter, how='outer',\n",
    "                   left_index=True, right_index=True).fillna(0)\n",
    "all_pkm['pkm'] = all_pkm['pkm_x'] + all_pkm['pkm_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "all_pkm[['pkm']].to_csv(output_path + 'pkm.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quetzal_env",
   "language": "python",
   "name": "quetzal_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
